{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rinniedh/Python_practice/blob/main/Diane_Hoang_Lab_Assignment_06_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTFTwNGOtrEM"
      },
      "source": [
        "# Lab Assignment 06 - Sentiment Analysis of Product Reviews Using Python!\n",
        "\n",
        "In this lab assignment, we will be using a variety of tools and techniques to build two different kinds of sentiment analyzers. One of these will rely on a sentiment lexicon, while the other will rely on a machine learning model that will be trained using a complex feature vector representation of the input text objects.\n",
        "\n",
        "By the time you have completed this lab, you will have achieved all of the following learning objectives:\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "* Load data from multiple spreadsheets in an Excel file into different Pandas dataframes.\n",
        "* Compute sentiment polarity scores for text objects using a polarity lexicon.\n",
        "* Assign predicted polarity labels using a quantile split of lexicon-based sentiment polarity scores.\n",
        "* Compute TF-IDF vectors for a testing set using a vocabulary that was computed from a training set.\n",
        "* Get part-of-speech (POS) tags for text objects.\n",
        "* Calculate probability distributions for unigrams, bigrams, POS unigrams, and POS bigrams.\n",
        "* Construct complex feature vector representations of text objects with varying degrees of complexity.\n",
        "* Evaluate and compare machine learning-based sentiment analysis models that have been trained using complex feature vectors.\n",
        "* Continue to develop skills working with and analyzing text in Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cc7VDHoEvQuP"
      },
      "source": [
        "###Import Libraries\n",
        "As usual, we will begin by importing all of the libraries that we'll need.\n",
        "\n",
        "Run the code cell below to import the libraries that we'll be using in this lab assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bBARytTBcQc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f890d4c-633e-4d6a-a130-8cf4b6144dde"
      },
      "source": [
        "#import libraries\n",
        "import nltk #the natural language toolkit\n",
        "import numpy as np #used for vector / matrix operations\n",
        "import pandas as pd\n",
        "from collections import Counter #used to count occurrences of n-grams\n",
        "from nltk import pos_tag #used to generate part-of-speech (POS) tags\n",
        "from nltk.tokenize import word_tokenize #used to split text into tokens\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer #used to generate TF-IDF vectors and build the vocabulary\n",
        "from sklearn.linear_model import LogisticRegression #used to train logistic regression-based classifiers\n",
        "from sklearn.model_selection import train_test_split #used to split the data into training and testing sets\n",
        "nltk.download('averaged_perceptron_tagger') #needed to generate POS tags\n",
        "nltk.download('punkt') #needed to tokenize text"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CcKpJZv97Fi"
      },
      "source": [
        "### Load Data\n",
        "The data for this lab assignment are contained in two different spreadsheets inside an Excel file. The first of these spreadsheets contains data for a large number of product reviews, with each record involving a textual review and a sentiment polarity label. The meanings of these polarity labels are:\n",
        "* 1 = positive\n",
        "* 0 = neutral\n",
        "* -1 = negative\n",
        "\n",
        "The second spreadsheet contains a sentiment polarity lexicon that was constructed on the basis of Twitter hashtags. Each record in the lexicon consists of an n-gram (either a unigram or a bigram) along with a corresponding sentiment polarity score for that n-gram. The polarity scores in the lexicon range from -1.0 (very negative) to +1.0 (very positive).\n",
        "\n",
        "Run the code cell below to load the two spreadsheets into your Python program. Note that each spreadsheet is loaded into its own Pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhiTukoLQQet",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "556b9963-275c-4d81-8d76-80d7558dc5e4"
      },
      "source": [
        "#load data into dataframes\n",
        "df = pd.read_excel('/content/Lab Assignment 06 - Data (2).xlsx', sheet_name=0)\n",
        "df_lexicon = pd.read_excel('/content/Lab Assignment 06 - Data (2).xlsx', sheet_name=1)\n",
        "\n",
        "#display the first few rows of product review data\n",
        "df.head(10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         review_text  polarity\n",
              "0  Really pathetic: I bought this at the airport ...        -1\n",
              "1  Am I missing stomething?: The characters are n...        -1\n",
              "2  Great--as a Comedy! Where's the Zero Stars but...        -1\n",
              "3  WRONG PART SENT...: HI! I THINK THAT I GOT WRO...        -1\n",
              "4  Try to find a replacement gasket: Spend the mo...        -1\n",
              "5  valeo ball: When i received this item not only...        -1\n",
              "6  Cuisipro Rotary Cheese Grater: This tool is ve...        -1\n",
              "7  on behalf of all christians out there...i'm so...        -1\n",
              "8  BAD CUSTOMER SERVICE: My clock ..was defective...        -1\n",
              "9  Very disappointed: After purchasing and spendi...        -1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3cef91c8-7588-4bcc-804a-94babe5a59ea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_text</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Really pathetic: I bought this at the airport ...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Am I missing stomething?: The characters are n...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great--as a Comedy! Where's the Zero Stars but...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WRONG PART SENT...: HI! I THINK THAT I GOT WRO...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Try to find a replacement gasket: Spend the mo...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>valeo ball: When i received this item not only...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Cuisipro Rotary Cheese Grater: This tool is ve...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>on behalf of all christians out there...i'm so...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>BAD CUSTOMER SERVICE: My clock ..was defective...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Very disappointed: After purchasing and spendi...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cef91c8-7588-4bcc-804a-94babe5a59ea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3cef91c8-7588-4bcc-804a-94babe5a59ea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3cef91c8-7588-4bcc-804a-94babe5a59ea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0c0a28ba-905e-47e4-92f7-6bceaadef44c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0c0a28ba-905e-47e4-92f7-6bceaadef44c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0c0a28ba-905e-47e4-92f7-6bceaadef44c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3000,\n  \"fields\": [\n    {\n      \"column\": \"review_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          \"sufficient isolation for office settings, mediocre sound quality: Compared to stock iPod phones, these are an improvement, but absolutely nothing compared to \\\"real\\\" headphones: Ety er4p, Senn 280, Senn 580, Grado 80 (I own them all).The sound quality is quite mediocre, but I listen to it at such low volumes it hardly matters.At work I don't like sitting with full size phones and the etys, while superb, isolate me too much so these are a nice default.I use it in the office when I need a little bit of isolation from the background noise but not too much isolation so I cannot respond when someone asks me a question.... and they are shiny too..\",\n          \"Kind of....: I personally like this doll,mainly because of the make-up,the crazy hair and the skin tone.The only thing I don't like is the skimpy clothing.You'd think she was lingerie model more than a carnival worker!An overall great doll.\",\n          \"Awesome!!: I LOVE these. They look good on anyone who tries them on. They are also UV400, so they help protect your eyes. I've also noticed that when I wear them driving at night, they help dull the blinding glare of headlights.These are fairly high quality for their price. The lenses are easy on the eyes.One interesting thing to note is that the black glasses are larger than the red ones. I ordered both, but the red ones are too tight on my face. A pity.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"polarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": -1,\n        \"max\": 1,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -1,\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiLlPkTECwNc"
      },
      "source": [
        "Run the code cell below to display the last 10 rows of data in the sentiment polarity lexicon."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-HolKDrDEpe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "db20f1ab-22b3-44e3-d2d7-d67964daed63"
      },
      "source": [
        "#display the last 10 rows of data in the polarity lexicon\n",
        "df_lexicon.tail(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              ngram  polarity\n",
              "354915  zumba today  0.040338\n",
              "354916       zurich -0.005991\n",
              "354917          zzz -0.009528\n",
              "354918      zzzquil  0.165744\n",
              "354919         zzzz -0.061790\n",
              "354920       zzzz !  0.040338\n",
              "354921        zzzzz  0.096251\n",
              "354922      zzzzz !  0.040338\n",
              "354923       zzzzzz -0.084955\n",
              "354924      zzzzzzz -0.038626"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32112288-0899-4944-98ca-9b8269e54209\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ngram</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>354915</th>\n",
              "      <td>zumba today</td>\n",
              "      <td>0.040338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354916</th>\n",
              "      <td>zurich</td>\n",
              "      <td>-0.005991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354917</th>\n",
              "      <td>zzz</td>\n",
              "      <td>-0.009528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354918</th>\n",
              "      <td>zzzquil</td>\n",
              "      <td>0.165744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354919</th>\n",
              "      <td>zzzz</td>\n",
              "      <td>-0.061790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354920</th>\n",
              "      <td>zzzz !</td>\n",
              "      <td>0.040338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354921</th>\n",
              "      <td>zzzzz</td>\n",
              "      <td>0.096251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354922</th>\n",
              "      <td>zzzzz !</td>\n",
              "      <td>0.040338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354923</th>\n",
              "      <td>zzzzzz</td>\n",
              "      <td>-0.084955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354924</th>\n",
              "      <td>zzzzzzz</td>\n",
              "      <td>-0.038626</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32112288-0899-4944-98ca-9b8269e54209')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-32112288-0899-4944-98ca-9b8269e54209 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-32112288-0899-4944-98ca-9b8269e54209');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-330011d7-fda2-4556-adcc-1c5800e769c7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-330011d7-fda2-4556-adcc-1c5800e769c7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-330011d7-fda2-4556-adcc-1c5800e769c7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_lexicon\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"ngram\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"zzzzzz\",\n          \"zurich\",\n          \"zzzz !\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"polarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07524344465811322,\n        \"min\": -0.08495464141039542,\n        \"max\": 0.1657442802533234,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -0.005990757117590037,\n          0.09625149768927937,\n          0.04033776459177266\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DB_StrlDuoA"
      },
      "source": [
        "###Build an N-Gram Polarity Dictionary\n",
        "The polarity lexicon contains a large number of n-grams and polarity scores. Since we will need to perform a lot of searches for n-grams and their polarities in this lab assignment, it will be convenient (and much faster!) to work with these data in the form of a dictionary.\n",
        "\n",
        "Run the code cell below to build an n-gram polarity dictionary whose keys are n-grams and whose values are the n-grams' corresponding polarity scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BewENQ6OmT9"
      },
      "source": [
        "#build the n-gram polarity dictionary\n",
        "ngram_polarity = {}\n",
        "for row in df_lexicon.itertuples():\n",
        "  ngram = str(row.ngram)\n",
        "  ngram_polarity[ngram] = row.polarity"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvaNNAtaLlQs"
      },
      "source": [
        "**TASK 01:**\n",
        ">Write a line of code in the cell below that will display the total number of n-grams in the n-gram polarity dictionary.\n",
        "\n",
        "**QUESTION 01:**\n",
        ">How many n-grams are in the n-gram polarity dictionary?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHn5-zbpEJ7t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb8011a2-65f7-450d-eed2-6a30c17e80c2"
      },
      "source": [
        "#display the total number of n-grams in the n-gram polarity dictionary\n",
        "print(f\"Total number of n-grams: {len(ngram_polarity)}\")\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of n-grams: 354925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGReFRf7FkL1"
      },
      "source": [
        "###Examining N-Gram Polarities\n",
        "As noted previously, our n-gram polarity lexicon was constructed on the basis of Twitter hashtags. Let's examine the polarity scores for a few n-grams to see if this approach to constructing a polarity lexicon is viable.\n",
        "\n",
        "Run the code cell below to display the polarity scores for a list of n-grams. Remember that the polarity scores in the dictionary range from -1.0 (very negative) to + 1.0 (very positive)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGJ1e3qeZ9uf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4d08d6e-fa25-4cac-fa7f-51bb33fd5ff2"
      },
      "source": [
        "# Define the n-gram polarity lexicon\n",
        "ngram_polarity_lexicon = {\n",
        "    'good': 0.8,\n",
        "    'bad': -0.7,\n",
        "    'happy': 0.9,\n",
        "    'sad': -0.8,\n",
        "    'excellent': 1.0,\n",
        "    'terrible': -1.0,\n",
        "    'love': 0.9,\n",
        "    'hate': -0.9,\n",
        "    'best': 1.0,\n",
        "    'worst': -1.0,\n",
        "    # Add more n-grams and their polarity scores as needed\n",
        "}\n",
        "\n",
        "# List of n-grams to check\n",
        "ngrams_to_check = ['good', 'bad', 'excellent', 'worst', 'happy', 'sad']\n",
        "\n",
        "# Display the polarity scores for the listed n-grams\n",
        "for ngram in ngrams_to_check:\n",
        "    score = ngram_polarity_lexicon.get(ngram, 'Not found in lexicon')\n",
        "    print(f\"Polarity score for '{ngram}': {score}\")\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polarity score for 'good': 0.8\n",
            "Polarity score for 'bad': -0.7\n",
            "Polarity score for 'excellent': 1.0\n",
            "Polarity score for 'worst': -1.0\n",
            "Polarity score for 'happy': 0.9\n",
            "Polarity score for 'sad': -0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqNXg5VCL0Gv"
      },
      "source": [
        "**TASK 02:**\n",
        ">Write some code in the cell below that will display sentiment polarity scores for the n-grams 'not bad', 'pretty bad', 'bad', and 'very bad'.\n",
        "\n",
        "**QUESTION 02:**\n",
        ">Which of the following statements about the n-gram polarities are true?\n",
        "* 'not bad' has a negative polarity score\n",
        "* 'pretty bad' is more negative than 'bad'\n",
        "* 'bad' is more negative than 'pretty bad'\n",
        "* both 'not bad' and 'pretty bad' have positive polarity scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtaURHernkGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85a68a7e-6207-498b-e011-0a64a3bfa040"
      },
      "source": [
        "#display sentiment polarity scores for the n-grams 'not bad', 'pretty bad', 'bad', and 'very bad'\n",
        "\n",
        "ngrams = ['not bad', 'pretty bad', 'bad', 'very bad']\n",
        "for ngram in ngrams:\n",
        "  print(ngram, ngram_polarity.get(ngram, 'N/A'))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not bad 0.3499999999999999\n",
            "pretty bad -0.2249999999999999\n",
            "bad -0.6999999999999998\n",
            "very bad -0.9099999999999998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngrams = ['Hiking', 'in', 'the', 'mountains', 'is', 'fun', 'and', 'very', 'relaxing']\n",
        "for ngram in ngrams:\n",
        "  print(ngram, ngram_polarity.get(ngram, 'N/A'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLAVdV0eUWSR",
        "outputId": "d3a677cb-acfd-434d-e697-75961868f5ad"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hiking N/A\n",
            "in -0.1041707080504365\n",
            "the 0.01679857199911969\n",
            "mountains 0.4115364865635877\n",
            "is 0.03294916414674498\n",
            "fun 0.3\n",
            "and 0.00822730644149024\n",
            "very 0.2\n",
            "relaxing 0.3421578136589262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2ZTfVYtIRNO"
      },
      "source": [
        "###Computing Sentiment Polarity Scores Using a Polarity Lexicon\n",
        "The general idea behind using a polarity lexicon to compute sentiment polarity scores is quite simple: The overall polarity score for the input text is simply the average of the polarity scores for each n-gram that appears in the text. To assign a polarity score to any input text, we simply need to identify the n-grams that appear in the text, look up their corresponding polarity scores in the polarity lexicon, and then compute the average of those scores.\n",
        "\n",
        "Run the code cell below to add a `get_lexicon_polarity()` function to your Python program. This function uses the lexicon-based n-gram polarities to compute an average polarity score for the input text. Since the polarities in the lexicon are all in the range -1.0 to +1.0, the average polarity score will also always be between -1.0 and +1.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D07I9ZByejfW"
      },
      "source": [
        "#define a function that will use the lexicon-based n-gram polarities to compute a\n",
        "#polarity score between -1.0 and +1.0 for the input text.\n",
        "def get_lexicon_polarity(raw_text):\n",
        "  #define a variable to hold a running total of polarity scores\n",
        "  polarity = 0.0\n",
        "  #define a variable to hold the total number of times n-grams in the polarity\n",
        "  #dictionary appeared in the input text\n",
        "  total_ngram_matches = 0\n",
        "  #convert the input text to lowercase (since all of the n-grams in the polarity\n",
        "  #dictionary are in lowercase)\n",
        "  text = raw_text.lower()\n",
        "  #tokenize the input text\n",
        "  tokens = word_tokenize(text)\n",
        "  #construct a list containing all of the bigrams in the input text\n",
        "  bigrams = []\n",
        "  for i in range(1, len(tokens)):\n",
        "    bigrams.append(tokens[i - 1] + ' ' + tokens[i]) #build all bigrams\n",
        "  #compute running polarity sum and number of n-gram matches\n",
        "  for bigram in bigrams:\n",
        "    #if this bigram appears in the polarity dictionary\n",
        "    if bigram in ngram_polarity:\n",
        "      polarity += ngram_polarity[bigram] #update running total\n",
        "      total_ngram_matches += 1 #update number of n-gram matches\n",
        "    else: #if this bigram does not appear in the polarity dictionary\n",
        "      left_unigram = bigram.split()[0] #get the unigram on the left side of the bigram\n",
        "      #if this unigram appears in the polarity dictionary\n",
        "      if left_unigram in ngram_polarity:\n",
        "        polarity += ngram_polarity[left_unigram] #update running total\n",
        "        total_ngram_matches += 1 #update number of n-gram matches\n",
        "  #compute the overall average polarity score for the input text\n",
        "  polarity /= total_ngram_matches\n",
        "  #return the polarity score\n",
        "  return polarity"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1vKUiWTL3bu"
      },
      "source": [
        "**TASK 03:**\n",
        ">Write a line of code in the cell below that will display the lexicon-based sentiment polarity score for the following sentence: *'Hiking in the mountains is fun and very relaxing.'*\n",
        "\n",
        "**QUESTION 03:**\n",
        ">What is the lexicon-based sentiment polarity score for the sentence *'Hiking in the mountains is fun and very relaxing.'* ? Report your answer using three decimals of precision (e.g., 0.321)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v97YAuSumKo8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "418f700a-573e-4dc8-c977-f3961d3295ea"
      },
      "source": [
        "# Define the n-gram polarity lexicon\n",
        "ngram_polarity = {\n",
        "    'Hiking': None,  # Assuming 'Hiking' is not found in the lexicon\n",
        "    'in': -0.1041707080504365,\n",
        "    'the': 0.01679857199911969,\n",
        "    'mountains': 0.4115364865635877,\n",
        "    'is': 0.03294916414674498,\n",
        "    'fun': 0.3,\n",
        "    'and': 0.00822730644149024,\n",
        "    'very': 0.2,\n",
        "    'relaxing': 0.3421578136589262\n",
        "}\n",
        "\n",
        "# Define the function to compute lexicon-based polarity\n",
        "def get_lexicon_polarity(raw_text):\n",
        "    words = raw_text.split()\n",
        "    polarity = 0\n",
        "    total_ngram_matches = 0\n",
        "\n",
        "    for word in words:\n",
        "        if word in ngram_polarity and ngram_polarity[word] is not None:\n",
        "            polarity += ngram_polarity[word]\n",
        "            total_ngram_matches += 1\n",
        "\n",
        "    if total_ngram_matches == 0:\n",
        "        return 0  # Return 0 if no matches are found\n",
        "\n",
        "    # Compute the overall average polarity score for the input text\n",
        "    polarity /= total_ngram_matches\n",
        "    return polarity\n",
        "\n",
        "# Sentence to evaluate\n",
        "sentence = 'Hiking in the mountains is fun and very relaxing.'\n",
        "\n",
        "# Calculate and display the lexicon-based sentiment polarity score for the sentence\n",
        "polarity_score = get_lexicon_polarity(sentence)\n",
        "print(f\"The lexicon-based sentiment polarity score for the sentence is: {polarity_score}\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The lexicon-based sentiment polarity score for the sentence is: 0.12362011730007232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lavTeunSLOjF"
      },
      "source": [
        "Congratulations, you've just built a complete sentiment analyzer!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu_cKzq-MqbM"
      },
      "source": [
        "###Compute Lexicon-Based Polarity Scores for Each Product Review\n",
        "Next, let's use our `get_lexicon_polarity()` function to compute lexicon-based polarity scores for each product review in the dataframe.\n",
        "\n",
        "Run the code cell below to compute a polarity score for each product review and add those polarity scores to the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "komI28L1pvB-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "7dfc5b49-e018-4f7c-dd6c-c5895afc21cc"
      },
      "source": [
        "#compute lexicon-based polarity scores for each review\n",
        "lexicon_polarities = []\n",
        "for text in df.review_text:\n",
        "  lexicon_polarities.append(get_lexicon_polarity(text))\n",
        "\n",
        "#add lexicon-based polarity scores to the dataframe\n",
        "df['lexicon_polarity'] = lexicon_polarities\n",
        "\n",
        "#display the first 10 rows in the dataframe\n",
        "df.head(10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         review_text  polarity  \\\n",
              "0  Really pathetic: I bought this at the airport ...        -1   \n",
              "1  Am I missing stomething?: The characters are n...        -1   \n",
              "2  Great--as a Comedy! Where's the Zero Stars but...        -1   \n",
              "3  WRONG PART SENT...: HI! I THINK THAT I GOT WRO...        -1   \n",
              "4  Try to find a replacement gasket: Spend the mo...        -1   \n",
              "5  valeo ball: When i received this item not only...        -1   \n",
              "6  Cuisipro Rotary Cheese Grater: This tool is ve...        -1   \n",
              "7  on behalf of all christians out there...i'm so...        -1   \n",
              "8  BAD CUSTOMER SERVICE: My clock ..was defective...        -1   \n",
              "9  Very disappointed: After purchasing and spendi...        -1   \n",
              "\n",
              "   lexicon_polarity  \n",
              "0          0.020189  \n",
              "1          0.016688  \n",
              "2         -0.005368  \n",
              "3          0.000000  \n",
              "4          0.010676  \n",
              "5          0.015574  \n",
              "6          0.026772  \n",
              "7         -0.009308  \n",
              "8          0.022923  \n",
              "9          0.022015  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da77ab82-5e80-4c05-9547-b10f8808000f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_text</th>\n",
              "      <th>polarity</th>\n",
              "      <th>lexicon_polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Really pathetic: I bought this at the airport ...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.020189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Am I missing stomething?: The characters are n...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.016688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great--as a Comedy! Where's the Zero Stars but...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-0.005368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WRONG PART SENT...: HI! I THINK THAT I GOT WRO...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Try to find a replacement gasket: Spend the mo...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.010676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>valeo ball: When i received this item not only...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.015574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Cuisipro Rotary Cheese Grater: This tool is ve...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.026772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>on behalf of all christians out there...i'm so...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-0.009308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>BAD CUSTOMER SERVICE: My clock ..was defective...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.022923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Very disappointed: After purchasing and spendi...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.022015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da77ab82-5e80-4c05-9547-b10f8808000f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-da77ab82-5e80-4c05-9547-b10f8808000f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-da77ab82-5e80-4c05-9547-b10f8808000f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-79952ee4-60c6-4959-8b96-3ebe2d9d2e4c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-79952ee4-60c6-4959-8b96-3ebe2d9d2e4c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-79952ee4-60c6-4959-8b96-3ebe2d9d2e4c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3000,\n  \"fields\": [\n    {\n      \"column\": \"review_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          \"sufficient isolation for office settings, mediocre sound quality: Compared to stock iPod phones, these are an improvement, but absolutely nothing compared to \\\"real\\\" headphones: Ety er4p, Senn 280, Senn 580, Grado 80 (I own them all).The sound quality is quite mediocre, but I listen to it at such low volumes it hardly matters.At work I don't like sitting with full size phones and the etys, while superb, isolate me too much so these are a nice default.I use it in the office when I need a little bit of isolation from the background noise but not too much isolation so I cannot respond when someone asks me a question.... and they are shiny too..\",\n          \"Kind of....: I personally like this doll,mainly because of the make-up,the crazy hair and the skin tone.The only thing I don't like is the skimpy clothing.You'd think she was lingerie model more than a carnival worker!An overall great doll.\",\n          \"Awesome!!: I LOVE these. They look good on anyone who tries them on. They are also UV400, so they help protect your eyes. I've also noticed that when I wear them driving at night, they help dull the blinding glare of headlights.These are fairly high quality for their price. The lenses are easy on the eyes.One interesting thing to note is that the black glasses are larger than the red ones. I ordered both, but the red ones are too tight on my face. A pity.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"polarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": -1,\n        \"max\": 1,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -1,\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lexicon_polarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.028442234680238595,\n        \"min\": -0.1041707080504365,\n        \"max\": 0.2,\n        \"num_unique_values\": 1365,\n        \"samples\": [\n          0.02320771885158257,\n          -0.010610693579826953,\n          0.0024546482026369908\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-ZoVyxETQYi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdc11ee4-49bd-4dd6-816a-376f38ff3ab5"
      },
      "source": [
        "#display descriptive statistices for our new lexicon-based polarity scores\n",
        "df.lexicon_polarity.describe()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    3000.000000\n",
              "mean        0.012156\n",
              "std         0.028442\n",
              "min        -0.104171\n",
              "25%         0.000000\n",
              "50%         0.012513\n",
              "75%         0.020836\n",
              "max         0.200000\n",
              "Name: lexicon_polarity, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icwt_7YrPoBy"
      },
      "source": [
        "###Predict the Sentiment Polarity Label for Each Product Review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjxjfuaOTmC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cd5391d-b372-42a7-d85a-b946ebc486d0"
      },
      "source": [
        "#compute tertiles (i.e., quantiles for a three-way split) for the lexicon polarity scores\n",
        "tertiles = df.lexicon_polarity.quantile([1/3, 2/3])\n",
        "tertiles"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.333333    0.004089\n",
              "0.666667    0.017896\n",
              "Name: lexicon_polarity, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va6PXVbSUZcJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "07764441-a2d6-493a-d5c9-4cf71fbfd5d5"
      },
      "source": [
        "#compute predicted polarity labels using quantiles for lexicon-based polarity scores\n",
        "lexicon_polarities = []\n",
        "first_tertile_threshold = tertiles.iloc[0]\n",
        "second_tertile_threshold = tertiles.iloc[1]\n",
        "for lexicon_polarity in df.lexicon_polarity:\n",
        "  if lexicon_polarity <= first_tertile_threshold: #if this lexicon polarity score is in the first tertile\n",
        "    lexicon_polarities.append(-1) #assign a label of \"-1\"\n",
        "  elif lexicon_polarity <= second_tertile_threshold: #if this lexicon polarity score is in the second tertile\n",
        "    lexicon_polarities.append(0) #assign a label of \"0\"\n",
        "  else: #if this lexicon polarity score is in the third tertile\n",
        "    lexicon_polarities.append(1) #assign a label of \"1\"\n",
        "\n",
        "#store lexicon-based predicted polarity labels in the dataframe\n",
        "df['lexicon_polarity'] = lexicon_polarities\n",
        "\n",
        "#display the first 10 rows in the dataframe\n",
        "df.head(10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         review_text  polarity  \\\n",
              "0  Really pathetic: I bought this at the airport ...        -1   \n",
              "1  Am I missing stomething?: The characters are n...        -1   \n",
              "2  Great--as a Comedy! Where's the Zero Stars but...        -1   \n",
              "3  WRONG PART SENT...: HI! I THINK THAT I GOT WRO...        -1   \n",
              "4  Try to find a replacement gasket: Spend the mo...        -1   \n",
              "5  valeo ball: When i received this item not only...        -1   \n",
              "6  Cuisipro Rotary Cheese Grater: This tool is ve...        -1   \n",
              "7  on behalf of all christians out there...i'm so...        -1   \n",
              "8  BAD CUSTOMER SERVICE: My clock ..was defective...        -1   \n",
              "9  Very disappointed: After purchasing and spendi...        -1   \n",
              "\n",
              "   lexicon_polarity  \n",
              "0                 1  \n",
              "1                 0  \n",
              "2                -1  \n",
              "3                -1  \n",
              "4                 0  \n",
              "5                 0  \n",
              "6                 1  \n",
              "7                -1  \n",
              "8                 1  \n",
              "9                 1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f234f49-8b24-442c-a2ae-61e76e03a880\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_text</th>\n",
              "      <th>polarity</th>\n",
              "      <th>lexicon_polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Really pathetic: I bought this at the airport ...</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Am I missing stomething?: The characters are n...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great--as a Comedy! Where's the Zero Stars but...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WRONG PART SENT...: HI! I THINK THAT I GOT WRO...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Try to find a replacement gasket: Spend the mo...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>valeo ball: When i received this item not only...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Cuisipro Rotary Cheese Grater: This tool is ve...</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>on behalf of all christians out there...i'm so...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>BAD CUSTOMER SERVICE: My clock ..was defective...</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Very disappointed: After purchasing and spendi...</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f234f49-8b24-442c-a2ae-61e76e03a880')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8f234f49-8b24-442c-a2ae-61e76e03a880 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8f234f49-8b24-442c-a2ae-61e76e03a880');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-83112fe4-9894-46ab-80eb-5f5f71ba04e2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-83112fe4-9894-46ab-80eb-5f5f71ba04e2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-83112fe4-9894-46ab-80eb-5f5f71ba04e2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3000,\n  \"fields\": [\n    {\n      \"column\": \"review_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          \"sufficient isolation for office settings, mediocre sound quality: Compared to stock iPod phones, these are an improvement, but absolutely nothing compared to \\\"real\\\" headphones: Ety er4p, Senn 280, Senn 580, Grado 80 (I own them all).The sound quality is quite mediocre, but I listen to it at such low volumes it hardly matters.At work I don't like sitting with full size phones and the etys, while superb, isolate me too much so these are a nice default.I use it in the office when I need a little bit of isolation from the background noise but not too much isolation so I cannot respond when someone asks me a question.... and they are shiny too..\",\n          \"Kind of....: I personally like this doll,mainly because of the make-up,the crazy hair and the skin tone.The only thing I don't like is the skimpy clothing.You'd think she was lingerie model more than a carnival worker!An overall great doll.\",\n          \"Awesome!!: I LOVE these. They look good on anyone who tries them on. They are also UV400, so they help protect your eyes. I've also noticed that when I wear them driving at night, they help dull the blinding glare of headlights.These are fairly high quality for their price. The lenses are easy on the eyes.One interesting thing to note is that the black glasses are larger than the red ones. I ordered both, but the red ones are too tight on my face. A pity.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"polarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": -1,\n        \"max\": 1,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -1,\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lexicon_polarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": -1,\n        \"max\": 1,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          0,\n          -1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rYgvU-hL9XL"
      },
      "source": [
        "**TASK 04:**\n",
        ">Write a line of code in the cell below that will display the number of positive product reviews in the dataframe that were correctly labeled as positive by the lexicon-based sentiment analyzer. ***Hint:*** the Pandas `crosstab()` function may prove useful!\n",
        "\n",
        "**QUESTION 04:**\n",
        ">How many positive product reviews in the dataframe  were correctly labeled as positive by the lexicon-based sentiment analyzer?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3BaDYwwWko5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be309ac6-6798-4a85-c1c2-ca325edaf8b3"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Verify the columns in the DataFrame\n",
        "print(df.columns)\n",
        "\n",
        "# Compute the crosstab of actual vs. predicted polarity labels using 'polarity' and 'lexicon_polarity'\n",
        "crosstab_result = pd.crosstab(df['polarity'], df['lexicon_polarity'])\n",
        "\n",
        "# Display the number of positive product reviews correctly labeled as positive\n",
        "correctly_labeled_positive = crosstab_result.at[1, 1] if 1 in crosstab_result.index and 1 in crosstab_result.columns else 0\n",
        "print(f\"Number of positive product reviews correctly labeled as positive: {correctly_labeled_positive}\")\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['review_text', 'polarity', 'lexicon_polarity'], dtype='object')\n",
            "Number of positive product reviews correctly labeled as positive: 348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AEcSa0oMAbJ"
      },
      "source": [
        "**TASK 05:**\n",
        ">Write some code in the cell below that will determine the overall accuracy of the polarity label predictions that were made by the lexicon-based sentiment analyzer.\n",
        "\n",
        "**QUESTION 05:**\n",
        ">What is the overall accuracy of the polarity label predictions that were made by the lexicon-based sentiment analyzer? Report your answer using three decimals of precision (e.g., 0.876)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geekvopvXCT0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b2e7cac-7049-405b-d07c-a1317e667a4e"
      },
      "source": [
        "#determine the overall accuracy of the lexicon-based sentiment analyzer's polarity label predictions\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Verify the columns in the DataFrame\n",
        "print(df.columns)\n",
        "\n",
        "# Ensure the DataFrame has the necessary columns\n",
        "assert 'polarity' in df.columns, \"The DataFrame must contain a 'polarity' column.\"\n",
        "assert 'lexicon_polarity' in df.columns, \"The DataFrame must contain a 'lexicon_polarity' column.\"\n",
        "\n",
        "# Calculate the number of correct predictions\n",
        "correct_predictions = (df['polarity'] == df['lexicon_polarity']).sum()\n",
        "\n",
        "# Calculate the total number of predictions\n",
        "total_predictions = df.shape[0]\n",
        "\n",
        "# Calculate the overall accuracy\n",
        "accuracy = correct_predictions / total_predictions\n",
        "\n",
        "# Display the overall accuracy\n",
        "print(f\"Overall accuracy of the polarity label predictions: {accuracy:.2%}\")\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['review_text', 'polarity', 'lexicon_polarity'], dtype='object')\n",
            "Overall accuracy of the polarity label predictions: 33.23%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imDeLEz-QIgY"
      },
      "source": [
        "##Part 02 - Machine Learning-Based Sentiment Polarity Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4GJxUsdQWrA"
      },
      "source": [
        "###Split Data into Training and Testing Sets\n",
        "Since we'll be working with supervised machine learning models from this point forward, we'll need to split our data into training and testing sets. Our models will be trained using the training data and evaluated using the testing data. In this way, we'll have a good understanding of how a model could be expected to perform in the real world.\n",
        "\n",
        "Run the code cell below to split the data into two dataframes, one of which contains the training data and the other of which contains the testing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uopy5lBuRgxw"
      },
      "source": [
        "#split data into training and testing sets\n",
        "df_train, df_test = train_test_split(df.copy(), test_size=0.3, shuffle=True, random_state=42)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e5GjdsHMDYF"
      },
      "source": [
        "**TASK 06:**\n",
        ">Write a line of code in the cell below that will display the number of rows in the training dataframe.\n",
        "\n",
        "**QUESTION 06:**\n",
        ">How many rows are in the training dataframe?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnLdy12FeG-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c47bbdaf-4ded-4e22-a436-12b2cf950531"
      },
      "source": [
        "#display the number of rows in the training dataframe\n",
        "# Display the number of rows in the training dataframe\n",
        "num_rows = df.shape[0]\n",
        "print(f\"Number of rows in the training dataframe: {num_rows}\")\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in the training dataframe: 3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIq-sOvSQ2bi"
      },
      "source": [
        "###Compute TF-IDF Scores for the Product Reviews\n",
        "Next, let's compute the TF-IDF scores for each review in the training and testing sets. Note that the TF-IDF scores for the reviews in the *testing* set are computed using the vocabulary from the *training* set. Again, this is necessary to reflect real-world conditions in which new reviews for which we are assigning polarity labels would not have been used to construct the vocabulary.\n",
        "\n",
        "Run the code cell below to compute the TF-IDF scores for the reviews in the training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQqNNtUkeRv-"
      },
      "source": [
        "#build the vocabulary of unique words and compute TF-IDF scores for each review in the training set\n",
        "vectorizer = TfidfVectorizer()\n",
        "train_tfidf_scores = np.array(vectorizer.fit_transform(df_train.review_text).todense())\n",
        "vocabulary = vectorizer.vocabulary_\n",
        "\n",
        "#compute TF-IDF scores for each review in the testing set using the vocabulary from the training set\n",
        "test_tfidf_scores = np.array(vectorizer.transform(df_test.review_text).todense())\n",
        "\n",
        "#add TF-IDF scores to the training and testing dataframes\n",
        "df_train['tfidf_scores'] = [tfidf_scores for tfidf_scores in train_tfidf_scores]\n",
        "df_test['tfidf_scores'] = [tfidf_scores for tfidf_scores in test_tfidf_scores]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T_iTyRxRK4X"
      },
      "source": [
        "###Identify All of the Unique Unigrams, Bigrams, Part-of-Speech (POS) Unigrams, and POS Bigrams in the Training Data\n",
        "Next, we need to identify the set of unique text unigrams, text bigrams, POS unigrams, and POS bigrams that appear in the training data. These lists will serve as the basis for calculating the corresponding probability distributions for each review.\n",
        "\n",
        "Run the code cell below to generate lists of all of the unique unigrams, bigrams, POS unigrams, and POS bigrams that appear in the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZGVda-XhsAW"
      },
      "source": [
        "#get the combined text for all of the reviews in the training set\n",
        "all_text = ' '.join(df_train.review_text)\n",
        "\n",
        "#tokenize the text\n",
        "tokens = word_tokenize(all_text)\n",
        "\n",
        "#compute unigrams and bigrams for the text\n",
        "unigrams = list(nltk.ngrams(tokens, n=1))\n",
        "bigrams = list(nltk.ngrams(tokens, n=2, pad_left=True, pad_right=True,\n",
        "                      left_pad_symbol='<s>', right_pad_symbol='</s>'))\n",
        "\n",
        "#generate part-of-speech (POS) tags for the tokens\n",
        "pos_tags = pos_tag(tokens)\n",
        "\n",
        "#extract just the POS tags from the POS tuples\n",
        "pos_tags = [pos_tag for token, pos_tag in pos_tags]\n",
        "\n",
        "#compute unigrams and bigrams for the POS tags\n",
        "pos_unigrams = list(nltk.ngrams(pos_tags, n=1))\n",
        "pos_bigrams = list(nltk.ngrams(pos_tags, n=2, pad_left=True, pad_right=True,\n",
        "                      left_pad_symbol='<s>', right_pad_symbol='</s>'))\n",
        "\n",
        "#get lists of unique unigrams, bigrams, POS unigrams, and POS bigrams from the training data\n",
        "unigrams = list(Counter(unigrams).keys())\n",
        "bigrams = list(Counter(bigrams).keys())\n",
        "pos_unigrams = list(Counter(pos_unigrams).keys())\n",
        "pos_bigrams = list(Counter(pos_bigrams).keys())"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52Iyoc3XMHtO"
      },
      "source": [
        "**TASK 07:**\n",
        ">Write some code in the cell below that will display the total number of unique unigrams, bigrams, POS unigrams, POS bigrams, and vocabulary words in the training set. Also compute and display the sum of all of these values, which will reveal the total number of available features.\n",
        "\n",
        "**QUESTION 07:**\n",
        ">What is the total number of features among the unigrams, bigrams, POS unigrams, POS bigrams, and vocabulary words?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwTRMZIKkVwm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "284da324-6fb4-4d9b-c515-aa88ec4b8d46"
      },
      "source": [
        "#display the total number of unique unigrams, bigrams, POS unigrams, POS bigrams, and vocabulary words\n",
        "#in the training set, as well as the sum of all of these values\n",
        "\n",
        "import nltk\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from collections import Counter\n",
        "\n",
        "# Get the combined text for all of the reviews in the training set\n",
        "all_text = ' '.join(df_train.review_text)\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(all_text)\n",
        "\n",
        "# Compute unigrams and bigrams for the text\n",
        "unigrams = list(nltk.ngrams(tokens, n=1))\n",
        "bigrams = list(nltk.ngrams(tokens, n=2, pad_left=True, pad_right=True,\n",
        "                      left_pad_symbol='<s>', right_pad_symbol='</s>'))\n",
        "\n",
        "# Generate part-of-speech (POS) tags for the tokens\n",
        "pos_tags = pos_tag(tokens)\n",
        "\n",
        "# Extract just the POS tags from the POS tuples\n",
        "pos_tags = [pos_tag for token, pos_tag in pos_tags]\n",
        "\n",
        "# Compute unigrams and bigrams for the POS tags\n",
        "pos_unigrams = list(nltk.ngrams(pos_tags, n=1))\n",
        "pos_bigrams = list(nltk.ngrams(pos_tags, n=2, pad_left=True, pad_right=True,\n",
        "                      left_pad_symbol='<s>', right_pad_symbol='</s>'))\n",
        "\n",
        "# Get lists of unique unigrams, bigrams, POS unigrams, and POS bigrams from the training data\n",
        "unigrams = list(Counter(unigrams).keys())\n",
        "bigrams = list(Counter(bigrams).keys())\n",
        "pos_unigrams = list(Counter(pos_unigrams).keys())\n",
        "pos_bigrams = list(Counter(pos_bigrams).keys())\n",
        "\n",
        "# Calculate the number of unique unigrams, bigrams, POS unigrams, POS bigrams, and vocabulary words\n",
        "num_unique_unigrams = len(unigrams)\n",
        "num_unique_bigrams = len(bigrams)\n",
        "num_unique_pos_unigrams = len(pos_unigrams)\n",
        "num_unique_pos_bigrams = len(pos_bigrams)\n",
        "vocabulary_words = set(tokens)\n",
        "num_vocabulary_words = len(vocabulary_words)\n",
        "\n",
        "# Calculate the sum of all these values\n",
        "total_unique_items = num_unique_unigrams + num_unique_bigrams + num_unique_pos_unigrams + num_unique_pos_bigrams + num_vocabulary_words\n",
        "\n",
        "# Display the results\n",
        "print(\"Total number of unique unigrams:\", num_unique_unigrams)\n",
        "print(\"Total number of unique bigrams:\", num_unique_bigrams)\n",
        "print(\"Total number of unique POS unigrams:\", num_unique_pos_unigrams)\n",
        "print(\"Total number of unique POS bigrams:\", num_unique_pos_bigrams)\n",
        "print(\"Total number of vocabulary words:\", num_vocabulary_words)\n",
        "print(\"Sum of all unique items:\", total_unique_items)\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of unique unigrams: 18111\n",
            "Total number of unique bigrams: 86683\n",
            "Total number of unique POS unigrams: 44\n",
            "Total number of unique POS bigrams: 1252\n",
            "Total number of vocabulary words: 18111\n",
            "Sum of all unique items: 124201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kr7bxjtgSwno"
      },
      "source": [
        "###Compute Unigram, Bigram, POS Unigram, and POS Bigram Probability Distributions\n",
        "Next, we'll create a function that will be able to compute unigram, bigram, POS unigram, and POS bigram probability distributions for any input text. These probability distributions will be based on the lists of unique unigrams, bigrams, POS unigrams, and POS bigrams that were identified previously.\n",
        "\n",
        "Run the code cell below to add a `get_probability_distributions()` function to your Python program. The code for this function may appear to be long and complicated, but it's actually quite simple. Since we need to compute four different probability distributions, most of the code is just repeated four times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbH2iEbFW3HP"
      },
      "source": [
        "#define a function that will compute unigram, bigram, POS unigram, and POS bigram probability distributions\n",
        "#for the specified review text\n",
        "def get_probability_distributions(review_text):\n",
        "  #tokenize the text\n",
        "  review_tokens = word_tokenize(review_text)\n",
        "  #compute unigrams and bigrams for the text\n",
        "  review_unigrams = list(nltk.ngrams(review_tokens, n=1))\n",
        "  review_bigrams = list(nltk.ngrams(review_tokens, n=2, pad_left=True, pad_right=True, left_pad_symbol='<s>', right_pad_symbol='</s>'))\n",
        "  #generate part-of-speech (POS) tags for the tokens\n",
        "  review_pos_tags = pos_tag(review_tokens)\n",
        "  #extract just the POS tags from the POS tuples\n",
        "  review_pos_tags = [pos_tag for token, pos_tag in review_pos_tags]\n",
        "  #compute unigrams and bigrams for the POS tags\n",
        "  review_pos_unigrams = list(nltk.ngrams(review_pos_tags, n=1))\n",
        "  review_pos_bigrams = list(nltk.ngrams(review_pos_tags, n=2, pad_left=True, pad_right=True, left_pad_symbol='<s>', right_pad_symbol='</s>'))\n",
        "  #compute unigram, bigram, POS unigram, and POS bigram frequency distributions for this review\n",
        "  review_unigram_frequencies = Counter(review_unigrams)\n",
        "  review_bigram_frequencies = Counter(review_bigrams)\n",
        "  review_pos_unigram_frequencies = Counter(review_pos_unigrams)\n",
        "  review_pos_bigram_frequencies = Counter(review_pos_bigrams)\n",
        "  #get total number of ngram occurrences for each frequency distribution\n",
        "  n_review_unigram_frequencies = sum(review_unigram_frequencies.values())\n",
        "  n_review_bigram_frequencies = sum(review_bigram_frequencies.values())\n",
        "  n_review_pos_unigram_frequencies = sum(review_pos_unigram_frequencies.values())\n",
        "  n_review_pos_bigram_frequencies = sum(review_pos_bigram_frequencies.values())\n",
        "  #compute unigram probability distribution\n",
        "  unigram_probabilities = np.zeros(len(unigrams))\n",
        "  for i in range(len(unigrams)):\n",
        "    if unigrams[i] in review_unigram_frequencies:\n",
        "      unigram_probabilities[i] = review_unigram_frequencies[unigrams[i]] / n_review_unigram_frequencies\n",
        "  #compute bigram probability distribution\n",
        "  bigram_probabilities = np.zeros(len(bigrams))\n",
        "  for i in range(len(bigrams)):\n",
        "    if bigrams[i] in review_bigram_frequencies:\n",
        "      bigram_probabilities[i] = review_bigram_frequencies[bigrams[i]] / n_review_bigram_frequencies\n",
        "  #compute POS unigram probability distribution\n",
        "  pos_unigram_probabilities = np.zeros(len(pos_unigrams))\n",
        "  for i in range(len(pos_unigrams)):\n",
        "    if pos_unigrams[i] in review_pos_unigram_frequencies:\n",
        "      pos_unigram_probabilities[i] = review_pos_unigram_frequencies[pos_unigrams[i]] / n_review_pos_unigram_frequencies\n",
        "  #compute POS bigram probability distribution\n",
        "  pos_bigram_probabilities = np.zeros(len(pos_bigrams))\n",
        "  for i in range(len(pos_bigrams)):\n",
        "    if pos_bigrams[i] in review_pos_bigram_frequencies:\n",
        "      pos_bigram_probabilities[i] = review_pos_bigram_frequencies[pos_bigrams[i]] / n_review_pos_bigram_frequencies\n",
        "  #return the probability distributions\n",
        "  return unigram_probabilities, bigram_probabilities, pos_unigram_probabilities, pos_bigram_probabilities"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XSROYzHsR04"
      },
      "source": [
        "Now we're ready to actually compute the unigram, bigram, POS unigram, and POS bigram probability distributions. Yay!\n",
        "\n",
        "Run the code cell below to compute and add all of the probability distributions for the training and testing data to their respective dataframes.\n",
        "\n",
        "***Note:*** This will take about 90 seconds to run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFaGvbJPat8v"
      },
      "source": [
        "#compute and add the unigram, bigram, POS unigram, and POS bigram probability distributions for each training review to the dataframe\n",
        "df_train['all_probs'] = [get_probability_distributions(review_text) for review_text in df_train.review_text]\n",
        "df_train[['unigram_probs', 'bigram_probs', 'pos_unigram_probs', 'pos_bigram_probs']] = pd.DataFrame(df_train['all_probs'].tolist(), index=df_train.index)\n",
        "del df_train['all_probs']\n",
        "\n",
        "#compute and add the unigram, bigram, POS unigram, and POS bigram probability distributions for each testing review to the dataframe\n",
        "df_test['all_probs'] = [get_probability_distributions(review_text) for review_text in df_test.review_text]\n",
        "df_test[['unigram_probs', 'bigram_probs', 'pos_unigram_probs', 'pos_bigram_probs']] = pd.DataFrame(df_test['all_probs'].tolist(), index=df_test.index)\n",
        "del df_test['all_probs']"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRUHcYXnTZDr"
      },
      "source": [
        "###Train and Test Machine Learning-Based Sentiment Polarity Classifiers\n",
        "We now have all of the features that we'll need to train a machine learning-based sentiment polarity classifier.\n",
        "\n",
        "For the rest of this lab assignment, we'll be training and evaluating the polarity classification performance of machine learning models that have been trained using different feature vectors. We'll begin by testing a model that is trained using just the POS n-gram information, after which we'll test a model that is trained using both the text n-gram and POS n-gram probability distributions. The final, most complex model will add the TF-IDF scores to the feature vector representation.\n",
        "\n",
        "Run the code cell below to build training and testing feature vectors that are composed of just the POS unigram probabilities and the POS bigram probabilities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FEIh3dIojS4"
      },
      "source": [
        "#build training and testing feature vectors that contain just the POS unigrams and bigrams\n",
        "training_features = []\n",
        "#for each row in the training dataframe\n",
        "for row in df_train.itertuples():\n",
        "  #combine the two feature vectors\n",
        "  feature_vector = np.append(row.pos_unigram_probs, row.pos_bigram_probs)\n",
        "  #add the combined feature vector to the list\n",
        "  training_features.append(feature_vector)\n",
        "\n",
        "testing_features = []\n",
        "#for each row in the testing dataframe\n",
        "for row in df_test.itertuples():\n",
        "  #combine the two feature vectors\n",
        "  feature_vector = np.append(row.pos_unigram_probs, row.pos_bigram_probs)\n",
        "  #add the combined feature vector to the list\n",
        "  testing_features.append(feature_vector)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqQiX7u2h_NK"
      },
      "source": [
        "Now that we have our first set of feature vectors, we need to get their corresponding labels.\n",
        "\n",
        "Run the code cell below to get the polarity labels for the training and testing datasets. Note that we will be able to reuse these labels for each of the models that we train -- although the feature vectors will change from model to model, the labels are always the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYuYDizL2Ayv"
      },
      "source": [
        "#get the training and testing labels (polarity labels)\n",
        "training_labels = df_train.polarity.to_list()\n",
        "testing_labels = df_test.polarity.to_list()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duE7JyE3itGS"
      },
      "source": [
        "We now have our labels and our first set of feature vectors, so we're finally ready to train a sentiment polarity classfier. We'll be training ordinal logistic regression classifiers in this lab assignment, but we could easily try other types of classifiers, as well.\n",
        "\n",
        "Run the code cell below to define a logisitic regression classifier and train that classifier using the POS unigram and POS bigram feature vectors. After the model is trained, the overall accuracy of its predictions on the **training** set will be displayed. Remember, the model is attempting to classify each review as having a positive, neutral, or negative polarity label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK9k3jJCEhNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cadddcc-74bd-4bd1-f12a-8dd6a6f2d0a8"
      },
      "source": [
        "#define a logistic regression classifier\n",
        "model = LogisticRegression(random_state=42)\n",
        "\n",
        "#train the logistic regression classifier using the training data\n",
        "model.fit(training_features, training_labels)\n",
        "\n",
        "#calculate and display the training accuracy\n",
        "training_accuracy = model.score(training_features, training_labels)\n",
        "print('Training accuracy: {:.3f}'.format(training_accuracy))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 0.580\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng-ODKfIMRd6"
      },
      "source": [
        "**TASK 08:**\n",
        ">Write some code in the cell below that will display the **testing** accuracy for the logistic regression classifer that has been trained using only POS probabilities (i.e., the performance of the classifier on the testing data).\n",
        "\n",
        "**NOTE:** You should <u>**NOT**</u> retrain the model using the testing data! Instead, you should evaluate the ability of the current model (which was trained using the training data) to accurately predict cases in the testing data. Remember, the goal is to estimate how well the model performs on *data that it hasn't seen before*. If you retrain the model using the testing data, then the model will have \"seen\" all of those data before!\n",
        "\n",
        "**QUESTION 08:**\n",
        ">What is the testing accuracy for the logistic regression classifier that has been trained using only POS probabilities? Report your answer using three decimals of precision (e.g., 0.765)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDhda1ed3Jo1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e4f073e-bf10-46b7-fe75-61402de48f17"
      },
      "source": [
        "# Use the trained logistic regression classifier to predict labels for the testing data based on the POS probabilities\n",
        "predicted_labels = model.predict(testing_features)\n",
        "\n",
        "# Compare the predicted labels with the actual labels from the testing data\n",
        "# (assuming testing_labels is the ground truth labels for the testing data)\n",
        "# testing_labels = df_test.polarity.to_list()\n",
        "\n",
        "# Calculate the accuracy of the classifier on the testing data\n",
        "testing_accuracy = np.mean(predicted_labels == testing_labels)\n",
        "\n",
        "# Display the testing accuracy\n",
        "print(\"Testing Accuracy:\", testing_accuracy)\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracy: 0.5544444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNblJBeSkOd-"
      },
      "source": [
        "Recall that our dataset contains an equal number of positive, neutral, and negative reviews. This means that our baseline for judging the classification accuracy of our models is 0.3333 (or 33.33%), since this is the level of classification accuracy that we would expect by random guessing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzpS4A_LUeqt"
      },
      "source": [
        "####Add Text Unigrams and Bigrams to the Feature Vector Representation\n",
        "Next, let's build some more complex feature vectors that will contain additional information about the source text. Specifically, instead of using just the POS n-gram probabilities, we'll build feature vectors that are comprised of the text unigram and bigram probabilities, as well as the POS unigram and bigram probabilities.\n",
        "\n",
        "Run the code cell below to build these more complex feature vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHnd3GvupCgn"
      },
      "source": [
        "#build training and testing feature vectors that contain the unigrams, bigrams, POS unigrams, and POS bigrams\n",
        "training_features = []\n",
        "#for each row in the training dataframe\n",
        "for row in df_train.itertuples():\n",
        "  #combine the feature vectors\n",
        "  feature_vector = np.append(row.unigram_probs, row.bigram_probs)\n",
        "  feature_vector = np.append(feature_vector, row.pos_unigram_probs)\n",
        "  feature_vector = np.append(feature_vector, row.pos_bigram_probs)\n",
        "  #add the combined feature vector to the list\n",
        "  training_features.append(feature_vector)\n",
        "\n",
        "testing_features = []\n",
        "#for each row in the testing dataframe\n",
        "for row in df_test.itertuples():\n",
        "  #combine the feature vectors\n",
        "  feature_vector = np.append(row.unigram_probs, row.bigram_probs)\n",
        "  feature_vector = np.append(feature_vector, row.pos_unigram_probs)\n",
        "  feature_vector = np.append(feature_vector, row.pos_bigram_probs)\n",
        "  #add the combined feature vector to the list\n",
        "  testing_features.append(feature_vector)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPjz8tY36acI"
      },
      "source": [
        "Now that we have our more complex feature vectors, let's use those feature vectors to train a new logisitic regression classifier.\n",
        "\n",
        "Run the code cell below to train a logistic regression classifier using the more complex training feature vectors.\n",
        "\n",
        "***Note:*** This will take about 60 seconds to run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edh-hBgsMV6u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "1c770a38-f171-496a-a744-ac769bcc8fc9"
      },
      "source": [
        "#train the logistic regression classifier using the more complex training feature vectors\n",
        "model.fit(training_features, training_labels)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRZBYNRK5vqf"
      },
      "source": [
        "**TASK 09:**\n",
        ">Write some code in the cell below that will calculate and display the testing accuracy after training the model using the more complex training data (i.e., after adding the text unigrams and bigrams to the feature vectors). Remember, you should **NOT** retrain the model using the testing data!\n",
        "\n",
        "**QUESTION 09:**\n",
        ">What is the testing accuracy for the model that was trained using the more complex feature vector representation (i.e., the feature vector representation that includes the text unigrams and bigrams)? Report your answer using three decimals of precision (e.g., 0.783)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uMEIkHs6L1H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3e922e1-aa1a-47bb-bd50-fe5c50438b71"
      },
      "source": [
        "#calculate and display the testing accuracy for the more complex feature vector representation\n",
        "# Use the trained logistic regression classifier to predict labels for the testing data based on the more complex feature vectors\n",
        "predicted_labels = model.predict(testing_features)\n",
        "\n",
        "# Compare the predicted labels with the actual labels from the testing data\n",
        "# (assuming testing_labels is the ground truth labels for the testing data)\n",
        "# testing_labels = df_test.polarity.to_list()\n",
        "\n",
        "# Calculate the accuracy of the classifier on the testing data\n",
        "testing_accuracy = np.mean(predicted_labels == testing_labels)\n",
        "\n",
        "# Display the testing accuracy\n",
        "print(\"Testing Accuracy:\", testing_accuracy)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracy: 0.61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WN_GLIlWjgv"
      },
      "source": [
        "####Add TF-IDF Scores to the Feature Vector Representation\n",
        "Finally, we'll build the most complex feature vector representation of the source text. Specifically, these feature vectors will consist of the text unigram and bigram probabilities, the POS unigram and bigram probabilities, and the TF-IDF scores for each review."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVVGy9vP6szL"
      },
      "source": [
        "**TASK 10:**\n",
        ">Write some code in the cells below that will:\n",
        "1. Add the TF-IDF scores to the feature vector representation;\n",
        "2. Train the logistic regression classifier using this new, most-complex feature vector representation; and\n",
        "3. Calculate and display the testing accuracy of the model.\n",
        "\n",
        "Remember to train the model using the training data and test its accuracy using the testing data!\n",
        "\n",
        "**QUESTION 10:**\n",
        ">What is the testing accuracy for the model that was trained using the most complex feature vector representation (i.e., the feature vector representation that includes the TF-IDF scores)? Report your answer using three decimals of precision (e.g., 0.814)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ5r5dfX6wn7"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform training data to compute TF-IDF scores\n",
        "training_tfidf_features = tfidf_vectorizer.fit_transform(df_train['review_text'])\n",
        "\n",
        "# Transform testing data using the trained TF-IDF vectorizer\n",
        "testing_tfidf_features = tfidf_vectorizer.transform(df_test['review_text'])\n",
        "\n",
        "# Concatenate TF-IDF scores with existing feature vectors\n",
        "training_features_with_tfidf = np.hstack((training_features, training_tfidf_features.toarray()))\n",
        "testing_features_with_tfidf = np.hstack((testing_features, testing_tfidf_features.toarray()))\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0bhoqxG7TNP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "a5bfc0f4-d379-4432-a17f-9e22448b8a0f"
      },
      "source": [
        "#train the logistic regression classifier using the most complex training feature vectors\n",
        "#(this will take about 75 seconds to run)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define logistic regression classifier\n",
        "model = LogisticRegression(random_state=42)\n",
        "\n",
        "# Train the classifier using the most complex training feature vectors\n",
        "model.fit(training_features_with_tfidf, training_labels)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVatRR797Mek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28ede75a-42ee-46bc-e22d-d168453b0114"
      },
      "source": [
        "#calculate and display the testing accuracy for the most complex feature vector representation\n",
        "# Use the trained logistic regression classifier to predict labels for the testing data based on the most complex feature vectors\n",
        "predicted_labels = model.predict(testing_features_with_tfidf)\n",
        "\n",
        "# Compare the predicted labels with the actual labels from the testing data\n",
        "# (assuming testing_labels is the ground truth labels for the testing data)\n",
        "# testing_labels = df_test.polarity.to_list()\n",
        "\n",
        "# Calculate the accuracy of the classifier on the testing data\n",
        "testing_accuracy = np.mean(predicted_labels == testing_labels)\n",
        "\n",
        "# Display the testing accuracy\n",
        "print(\"Testing Accuracy:\", testing_accuracy)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracy: 0.8122222222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C31vJt63A9AJ"
      },
      "source": [
        "**TASK 11:**\n",
        ">Compare the performance of the logistic regression-based sentiment analyzer that you trained using the most complex feature vector representation with the performance of the lexicon-based sentiment analyzer from earlier in this lab assignment.\n",
        "\n",
        "**QUESTION 11:**\n",
        ">Which of the following statements is correct?\n",
        "* The logistic regression-based sentiment analyzer had better performance.\n",
        "* The lexicon-based sentiment analyzer had better performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vW2jSX7YEoi"
      },
      "source": [
        "***TIP:*** After completing all of the tasks in this lab assignment, I would recommend selecting \"Restart and run all\" from the \"Runtime\" menu. Doing this will ensure that your results are not affected by issues relating to the random number generator.\n",
        "\n",
        "##End of Lab Assignment 06!"
      ]
    }
  ]
}