{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rinniedh/Python_practice/blob/main/Lab_Assignment_05_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vuiYfgqb5_0"
      },
      "source": [
        "# Lab Assignment 05 - Automatic Text Summarization Using Python!\n",
        "\n",
        "In this lab assignment, we will be using a variety of tools and techniques to automatically generate summaries of text documents.\n",
        "\n",
        "By the time you have completed this lab, you will have achieved all of the following learning objectives:\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "* Become more familiar with the Natural Language Toolkit (NLTK).\n",
        "* Learn how to read data from a text file.\n",
        "* Learn how to split text into paragraphs and sentences.\n",
        "* Understand the challenges associated with sentence boundary disambiguation.\n",
        "* Learn how to generate feature vector representations of *sentences* (as opposed to documents).\n",
        "* Be able to compute a centroid for the sentences in a document.\n",
        "* Know how to compute Maximum Marginal Relevance (MMR) scores, and use those MMR scores to generate an extractive text summary.\n",
        "* Learn how to split a sentence into n-grams.\n",
        "* Know how to construct a language model based on n-grams.\n",
        "* Understand how to calculate conditional probabilities for n-grams, and how those probabilities can be used to select the next word in a sequence.\n",
        "* Be able to generate an abstractive text summary.\n",
        "* Continue to develop skills working with and analyzing text in Python.\n",
        "\n",
        "###Import Libraries\n",
        "Run the code cell below to install and import all of the libraries that we'll need for this lab assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cFvIbmPCreF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "951d920e-1955-4bce-e81e-a2c84dcf361d"
      },
      "source": [
        "#install the 'contractions' library\n",
        "!pip install contractions\n",
        "\n",
        "#import libraries\n",
        "import contractions\n",
        "import nltk #the natural language toolkit\n",
        "import numpy as np #used to generate random numbers\n",
        "import pandas as pd #used to store data in a dataframe\n",
        "import re #regular expressions; used to clean the text data\n",
        "import string #used to determine if a character is a punctuation symbol\n",
        "from nltk.probability import FreqDist #used to compute conditional frequency distributions\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize #used to split text into sentences, and to split sentences into words\n",
        "from nltk.util import ngrams #used to generate n-grams for each sentences\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer #used to generate TF-IDF vectors and build the vocabulary\n",
        "from sklearn.metrics.pairwise import cosine_similarity #used to compute cosine similarities\n",
        "\n",
        "#install nltk's 'punkt' tools, which are needed to tokenize sentences and words\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omdaVDNLVrUw"
      },
      "source": [
        "##Extractive Text Summarization\n",
        "In ***extractive text summarization***, the summary consists of a sequence of words or sentences that have been selected and extracted from the original text. Extractive text summarization relies on *sentence vectors* (as opposed to document vectors) and similarity functions in order to create a summary of the original text.\n",
        "\n",
        "The basic approach to extractive text summarization involves two steps:\n",
        "1. Split the original text into smaller sections or passages of text.\n",
        "2. For each passage of text, compress its sentences into a smaller number of sentences. This is accomplished by selecting the most representative sentence within the passage of text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ClNFgKcdTUN"
      },
      "source": [
        "###Load Data\n",
        "Run the code cell below to load the data for this part of the lab assignment. In this case, we'll be working with part of the Wikipedia article about the State of Washington."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5-7deOYVutZ"
      },
      "source": [
        "#load raw text from a file\n",
        "with open('Washington.txt', 'r') as f:\n",
        "  text = f.read()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxewGyy_d7DI"
      },
      "source": [
        "###Split Text Into Passages\n",
        "The first step in the extractive text summarization process is to split the raw text into passages. The simplest way of splitting text into passages is to rely on the text's existing paragraphs. Since paragraphs are used to divide a written document into smaller pieces that address a single topic or concept, using paragraphs as the basis for defining passages of text for our extractive summarization task is very natural.\n",
        "\n",
        "Paragraphs begin on a new line within a document, so we can use Python's new line character `\\n` (also called a *linefeed*) as a way of identifying the boundaries between paragraphs.\n",
        "\n",
        "**TASK 01**:\n",
        ">Run the code cell below to split the raw text into paragraphs, then write a line of code that will display the total number of paragraphs in the raw text.\n",
        "\n",
        "**QUESTION 01**:\n",
        ">How many paragraphs are in the article about the State of Washington?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ntz3Ty9RVv6o"
      },
      "source": [
        "#split text into paragraphs\n",
        "text = text.replace('\\n\\n', '\\n') #replace any double linefeeds with a single linefeed\n",
        "paragraphs = text.split('\\n') #use the linefeed character to split the text into paragraphs"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDh3Mhi9rvZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a3a5197-b005-40d7-f73c-26ddc8ee9c9a"
      },
      "source": [
        "#display the number of paragraphs in the raw text\n",
        "num_paragraphs = len(paragraphs)\n",
        "print(\"Number of paragraphs:\", num_paragraphs)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of paragraphs: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxdo6YnWk6yY"
      },
      "source": [
        "###Split Passages Into Sentences\n",
        "As noted above, extractive text summarization relies on *sentence vectors* (as opposed to document vectors). As such, we'll need to split each passage (paragraph) of text into sentences. **Don't be fooled into thinking that this is an easy task!** Accurately identifying the boundaries between sentences is a much subtler process than it may initially seem. At first, we may think that English has only three punctuation symbols that can end a sentence -- a period (full stop) `.`, an exclamation point `!`, and a question mark `?` -- and that we can therefore identify the end of a sentence just by looking for one of these symbols. Things are, however, not so simple. Consider the following sentences:\n",
        "* I enjoy books written by George R. R. Martin.\n",
        "* \"What time will you arrive?\", she asked.\n",
        "\n",
        "If we used our simple rules, then the first sentence above would be treated as three separate sentences:\n",
        "1. I enjoy books written by George R.\n",
        "2. R.\n",
        "3. Martin.\n",
        "\n",
        "...and the second sentence above would be treated as two separate sentences:\n",
        "1. \"What time will you arrive?\n",
        "2. \", she asked.\n",
        "\n",
        "As you can see, this problem is not as easy as it seems! The task of identifying the boundaries between sentences is known as ***sentence boundary disambiguation***. If you'd like to learn more, then please read [this article](https://en.wikipedia.org/wiki/Sentence_boundary_disambiguation).\n",
        "\n",
        "The good news is that researchers have created sophisticated tools that can accurately identify sentence boundaries. One of these tools is available in the **Natural Language Toolkit (NLTK)**, which we will use extensively in this lab assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWvxaNvKrDjq"
      },
      "source": [
        "**TASK 02**:\n",
        ">Run the code cell below to split each paragraph into sentences using NLTK's sentence tokenizer, then write some code that will calculate and display the average number of sentences per paragraph.\n",
        "\n",
        "**QUESTION 02**:\n",
        ">What is the average number of sentences per paragraph for the article about the State of Washington? Report your answer using three decimals of precision (e.g., 3.456)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVuINHIlVv2w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e47fa241-0094-4074-ee1c-bbae9e62dee2"
      },
      "source": [
        "#for each paragraph\n",
        "for i in range(len(paragraphs)):\n",
        "  #use NLTK's sentence tokenizer to split the current paragraph into sentences\n",
        "  paragraphs[i] = sent_tokenize(paragraphs[i])\n",
        "\n",
        "#display the sentences in the first paragraph\n",
        "paragraphs[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Washington, officially the State of Washington, is a state in the Pacific Northwest region of the Western United States.',\n",
              " 'Named for George Washington, the first U.S. president, the state was made out of the western part of the Washington Territory, which was ceded by the British Empire in 1846, in accordance with the Oregon Treaty in the settlement of the Oregon boundary dispute.',\n",
              " 'The state, which is bordered on the west by the Pacific Ocean, Oregon to the south, Idaho to the east, and the Canadian province of British Columbia to the north, was admitted to the Union as the 42nd state in 1889.',\n",
              " 'Olympia is the state capital.',\n",
              " \"The state's largest city is Seattle.\",\n",
              " \"Washington is often referred to as Washington state to distinguish it from the nation's capital, Washington, D.C.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diUboXF1Vvza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b658d9af-8648-42d9-d671-b0c62acc12b0"
      },
      "source": [
        "#calculate and display the average number of sentences per paragraph\n",
        "\n",
        "# Calculate the total number of sentences\n",
        "total_sentences = sum(len(sentences) for sentences in paragraphs)\n",
        "\n",
        "# Calculate the average number of sentences per paragraph\n",
        "average_sentences_per_paragraph = total_sentences / len(paragraphs)\n",
        "\n",
        "# Display the average number of sentences per paragraph\n",
        "print(\"Average number of sentences per paragraph:\", round(average_sentences_per_paragraph, 3))\n",
        "\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average number of sentences per paragraph: 4.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOhsPP0huimb"
      },
      "source": [
        "###Move Data to a DataFrame\n",
        "Next, let's move all of our sentences into a pandas dataframe so that they'll be easier to work with.\n",
        "\n",
        "Run the code cell below to add all of our sentences to a pandas dataframe. We'll also add a column named `sentence_id` that will record the order in which each sentence appeared in the original article, as well as a column named `paragraph_id` that will record the paragraph in which each sentence appeared in the original article."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5ti75eDVvvZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "f364b987-2bf5-4333-ee31-b6996d46b8fb"
      },
      "source": [
        "#construct the rows of data\n",
        "rows = []\n",
        "sentence_id = 0\n",
        "for paragraph_id in range(len(paragraphs)): #for each paragraph\n",
        "  for sentence in paragraphs[paragraph_id]: #for each sentence in the current paragraph\n",
        "    rows.append([sentence_id, paragraph_id, sentence]) #build a row of data\n",
        "    sentence_id += 1 #increment sentence ID\n",
        "\n",
        "#add the sentences to a dataframe\n",
        "df = pd.DataFrame(rows, columns=['sentence_id', 'paragraph_id', 'raw_text'])\n",
        "df.set_index('sentence_id', inplace=True) #use the sentence_id column as the dataframe's index\n",
        "\n",
        "#display the first few rows\n",
        "df.head(10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             paragraph_id                                           raw_text\n",
              "sentence_id                                                                 \n",
              "0                       0  Washington, officially the State of Washington...\n",
              "1                       0  Named for George Washington, the first U.S. pr...\n",
              "2                       0  The state, which is bordered on the west by th...\n",
              "3                       0                      Olympia is the state capital.\n",
              "4                       0               The state's largest city is Seattle.\n",
              "5                       0  Washington is often referred to as Washington ...\n",
              "6                       1  Washington is the 18th largest state, with an ...\n",
              "7                       1  Approximately 60 percent of Washington's resid...\n",
              "8                       1  The remainder of the state consists of deep te...\n",
              "9                       1  Washington is the second most populous state o..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-383feae0-123f-44dd-932c-9bc1b0e1e5d3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paragraph_id</th>\n",
              "      <th>raw_text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentence_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Washington, officially the State of Washington...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Named for George Washington, the first U.S. pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>The state, which is bordered on the west by th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Olympia is the state capital.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>The state's largest city is Seattle.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>Washington is often referred to as Washington ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>Washington is the 18th largest state, with an ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>Approximately 60 percent of Washington's resid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>The remainder of the state consists of deep te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>Washington is the second most populous state o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-383feae0-123f-44dd-932c-9bc1b0e1e5d3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-383feae0-123f-44dd-932c-9bc1b0e1e5d3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-383feae0-123f-44dd-932c-9bc1b0e1e5d3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-06ab0839-79d0-4453-a2f9-11cfb6fe6e74\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-06ab0839-79d0-4453-a2f9-11cfb6fe6e74')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-06ab0839-79d0-4453-a2f9-11cfb6fe6e74 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 22,\n  \"fields\": [\n    {\n      \"column\": \"sentence_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 0,\n        \"max\": 21,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0,\n          13,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paragraph_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raw_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"Washington, officially the State of Washington, is a state in the Pacific Northwest region of the Western United States.\",\n          \"Washington is the nation's largest producer of apples, hops, pears, red raspberries, spearmint oil, and sweet cherries, and ranks high in the production of apricots, asparagus, dry edible peas, grapes, lentils, peppermint oil, and potatoes.\",\n          \"The remainder of the state consists of deep temperate rainforests in the west, mountain ranges in the west, central, northeast, and far southeast, and a semi-arid basin region in the east, central, and south, given over to intensive agriculture.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFD-wir-Ae2-"
      },
      "source": [
        "###Clean Raw Text\n",
        "As usual, we'll need to clean our raw text before we can compute a feature vector representation for each sentence.\n",
        "\n",
        "Run the code cell below to add our `get_clean_text()` function to your Python program."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxTTSV7xVvn5"
      },
      "source": [
        "#define a function that will clean the raw input text in preparation for analysis. Returns a tuple containing\n",
        "#both the cleaned text and the total number of words in the cleaned text.\n",
        "def get_clean_text(raw_text, expand_contractions=True):\n",
        "  #if we need to expand any contractions in the input text (e.g., I'm --> I am)\n",
        "  if expand_contractions:\n",
        "    raw_text = contractions.fix(raw_text)\n",
        "  #find any period-separated acronyms (e.g., 'U.S.A.', 'L.A.', etc.)\n",
        "  period_separated_acronyms = re.findall(r'(?:[A-Z]\\.){2,}', raw_text)\n",
        "  #remove periods from any period-separated acronyms\n",
        "  for i in range(len(period_separated_acronyms)):\n",
        "    acronym = period_separated_acronyms[i].replace('.', '')\n",
        "    raw_text = raw_text.replace(period_separated_acronyms[i], acronym)\n",
        "  #remove all numbers from the text using a regular expression\n",
        "  text = re.sub(r'[0-9]', ' ', raw_text)\n",
        "  #remove all underscores from the text\n",
        "  text = re.sub(r'\\_', ' ', text)\n",
        "  #remove anything else in the text that isn't a word character or a space (e.g., punctuation, special symbols, etc.)\n",
        "  text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "  #remove any excess whitespace\n",
        "  for _ in range(10):\n",
        "    text = text.replace('  ', ' ')\n",
        "  #remove any leading or trailing space characters\n",
        "  text = text.strip()\n",
        "  #split the text into a list of words\n",
        "  words = text.split()\n",
        "  #convert all non-acronyms to lowercase\n",
        "  for i in range(len(words)): #for each index in the words collection\n",
        "    word = words[i] #define the current word\n",
        "    if len(word) > 1 and len(word) < 7: #if this word is two to six characters long\n",
        "      if word.isupper() == False: #if at least one character in this word is not uppercase\n",
        "        #this word is not an acronym because it is not all uppercase, so convert it to lowercase\n",
        "        words[i] = word.lower()\n",
        "    else: #this word is not an acronym because it consists of one letter or more than six letters, so convert it to lowercase\n",
        "      words[i] = word.lower()\n",
        "  #return the cleaned text and the number of words in the cleaned text\n",
        "  return (' '.join(words), len(words))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1SZ0HobBptP"
      },
      "source": [
        "Now that the `get_clean_text()` function has been made available to your Python program, you're ready to clean the raw text of each sentence.\n",
        "\n",
        "Run the code cell below to clean the raw text of each sentence and save the resulting cleaned text and the total number of words in the sentence to new columns in the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7f6Aas4Vvek",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "fdbe6eca-cbb2-43dc-9b34-8b3a7f6feb47"
      },
      "source": [
        "#clean the raw text of each sentence and save the resulting cleaned text and total number of words for\n",
        "#each sentence in new dataframe columns named 'clean_text' and 'total_words'.\n",
        "df[['clean_text', 'total_words']] = [get_clean_text(raw_text) for raw_text in df.raw_text]\n",
        "\n",
        "#show the first few rows in the dataframe\n",
        "df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             paragraph_id                                           raw_text  \\\n",
              "sentence_id                                                                    \n",
              "0                       0  Washington, officially the State of Washington...   \n",
              "1                       0  Named for George Washington, the first U.S. pr...   \n",
              "2                       0  The state, which is bordered on the west by th...   \n",
              "3                       0                      Olympia is the state capital.   \n",
              "4                       0               The state's largest city is Seattle.   \n",
              "\n",
              "                                                    clean_text total_words  \n",
              "sentence_id                                                                 \n",
              "0            washington officially the state of washington ...          19  \n",
              "1            named for george washington the first YOUS pre...          43  \n",
              "2            the state which is bordered on the west by the...          40  \n",
              "3                                 olympia is the state capital           5  \n",
              "4                          the state s largest city is seattle           7  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae9877e1-2c5d-44c2-ab06-0d242adc6f27\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paragraph_id</th>\n",
              "      <th>raw_text</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>total_words</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentence_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Washington, officially the State of Washington...</td>\n",
              "      <td>washington officially the state of washington ...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Named for George Washington, the first U.S. pr...</td>\n",
              "      <td>named for george washington the first YOUS pre...</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>The state, which is bordered on the west by th...</td>\n",
              "      <td>the state which is bordered on the west by the...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Olympia is the state capital.</td>\n",
              "      <td>olympia is the state capital</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>The state's largest city is Seattle.</td>\n",
              "      <td>the state s largest city is seattle</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae9877e1-2c5d-44c2-ab06-0d242adc6f27')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ae9877e1-2c5d-44c2-ab06-0d242adc6f27 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ae9877e1-2c5d-44c2-ab06-0d242adc6f27');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-884e6e1a-425f-4071-b89a-df1d8339df37\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-884e6e1a-425f-4071-b89a-df1d8339df37')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-884e6e1a-425f-4071-b89a-df1d8339df37 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 22,\n  \"fields\": [\n    {\n      \"column\": \"sentence_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 0,\n        \"max\": 21,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0,\n          13,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paragraph_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raw_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"Washington, officially the State of Washington, is a state in the Pacific Northwest region of the Western United States.\",\n          \"Washington is the nation's largest producer of apples, hops, pears, red raspberries, spearmint oil, and sweet cherries, and ranks high in the production of apricots, asparagus, dry edible peas, grapes, lentils, peppermint oil, and potatoes.\",\n          \"The remainder of the state consists of deep temperate rainforests in the west, mountain ranges in the west, central, northeast, and far southeast, and a semi-arid basin region in the east, central, and south, given over to intensive agriculture.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"washington officially the state of washington is a state in the pacific northwest region of the western united states\",\n          \"washington is the nation s largest producer of apples hops pears red raspberries spearmint oil and sweet cherries and ranks high in the production of apricots asparagus dry edible peas grapes lentils peppermint oil and potatoes\",\n          \"the remainder of the state consists of deep temperate rainforests in the west mountain ranges in the west central northeast and far southeast and a semi arid basin region in the east central and south given over to intensive agriculture\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_words\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 5,\n        \"max\": 59,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          19,\n          43,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7jkfIF6kmvh"
      },
      "source": [
        "###Sentence Length\n",
        "Research has shown that there is an inverse relationship between the number of words in a sentence and how easily a typical reader can understand the sentence. Specifically:\n",
        "* Sentences containing approximately 11 words are rated as *easy to understand*.\n",
        "* Sentences containing approximately 21 words are rated as *somewhat difficult to understand*.\n",
        "* Sentences containing approximately 25 words are rated as *difficult to understand*.\n",
        "* Sentences containing approximately 29 words or more are rated as *very difficult to understand*.\n",
        "\n",
        "In light of this information, let's evaluate the average sentence length among the sentences in our article about the State of Washington.\n",
        "\n",
        "**TASK 03**:\n",
        ">Write a line of code in the cell below that will display the average number of words per sentence.\n",
        "\n",
        "**QUESTION 03**:\n",
        ">What is the average number of words per sentence among the sentences in the article about the State of Washington? Report your answer using three decimals of precision (e.g., 18.678)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNPIoyLfChOL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "668e11cc-f4c1-4fc8-df8d-ee11b7b63dba"
      },
      "source": [
        "#display the average number of words per sentence\n",
        "\n",
        "average_words_per_sentence = df['total_words'].mean()\n",
        "print(\"Average number of words per sentence:\", round(average_words_per_sentence, 3))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average number of words per sentence: 24.636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3_A5xnbofwt"
      },
      "source": [
        "### Compute TF-IDF Scores & Build the Vocabulary\n",
        "Now we're ready to compute the TF-IDF scores for each sentence. Note that in previous assignments, we've computed TF-IDF scores for each *article* in a *corpus*. Our current task is conceptually similar, except that we'll be computing a TF-IDF vector for each *sentence* within an *article*. Each of these feature vectors, then, will describe the semantic content of its associated sentence relative to the article as a whole. This approach is necessary because extractive text summarization relies on sentence-level vectors instead of document-level vectors.\n",
        "\n",
        "Run the code cell below to build the vocabulary and compute and add a TF-IDF vector for each sentence to the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YU9H6yXuCg-7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "14c5d4fb-5409-4dc4-948b-950d3da98383"
      },
      "source": [
        "#build the vocabulary of unique words and compute TF-IDF scores for each sentence\n",
        "vectorizer = TfidfVectorizer(lowercase=False)\n",
        "sentence_tfidf_scores = np.array(vectorizer.fit_transform(df.clean_text).todense())\n",
        "vocabulary = vectorizer.vocabulary_\n",
        "\n",
        "#add each sentence's vector of TF-IDF scores to the dataframe\n",
        "df['tfidf_scores'] = [tfidf_scores for tfidf_scores in sentence_tfidf_scores]\n",
        "\n",
        "#display the first few rows\n",
        "df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             paragraph_id                                           raw_text  \\\n",
              "sentence_id                                                                    \n",
              "0                       0  Washington, officially the State of Washington...   \n",
              "1                       0  Named for George Washington, the first U.S. pr...   \n",
              "2                       0  The state, which is bordered on the west by th...   \n",
              "3                       0                      Olympia is the state capital.   \n",
              "4                       0               The state's largest city is Seattle.   \n",
              "\n",
              "                                                    clean_text total_words  \\\n",
              "sentence_id                                                                  \n",
              "0            washington officially the state of washington ...          19   \n",
              "1            named for george washington the first YOUS pre...          43   \n",
              "2            the state which is bordered on the west by the...          40   \n",
              "3                                 olympia is the state capital           5   \n",
              "4                          the state s largest city is seattle           7   \n",
              "\n",
              "                                                  tfidf_scores  \n",
              "sentence_id                                                     \n",
              "0            [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "1            [0.0, 0.1316039800009417, 0.0, 0.0, 0.16478488...  \n",
              "2            [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1708030013569...  \n",
              "3            [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "4            [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cddc4635-1146-4568-b0df-3f98b2d22138\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paragraph_id</th>\n",
              "      <th>raw_text</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>total_words</th>\n",
              "      <th>tfidf_scores</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentence_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Washington, officially the State of Washington...</td>\n",
              "      <td>washington officially the state of washington ...</td>\n",
              "      <td>19</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Named for George Washington, the first U.S. pr...</td>\n",
              "      <td>named for george washington the first YOUS pre...</td>\n",
              "      <td>43</td>\n",
              "      <td>[0.0, 0.1316039800009417, 0.0, 0.0, 0.16478488...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>The state, which is bordered on the west by th...</td>\n",
              "      <td>the state which is bordered on the west by the...</td>\n",
              "      <td>40</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1708030013569...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Olympia is the state capital.</td>\n",
              "      <td>olympia is the state capital</td>\n",
              "      <td>5</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>The state's largest city is Seattle.</td>\n",
              "      <td>the state s largest city is seattle</td>\n",
              "      <td>7</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cddc4635-1146-4568-b0df-3f98b2d22138')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cddc4635-1146-4568-b0df-3f98b2d22138 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cddc4635-1146-4568-b0df-3f98b2d22138');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d7189b80-e020-43f9-a15b-5d1c653203e8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d7189b80-e020-43f9-a15b-5d1c653203e8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d7189b80-e020-43f9-a15b-5d1c653203e8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 22,\n  \"fields\": [\n    {\n      \"column\": \"sentence_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 0,\n        \"max\": 21,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0,\n          13,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paragraph_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raw_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"Washington, officially the State of Washington, is a state in the Pacific Northwest region of the Western United States.\",\n          \"Washington is the nation's largest producer of apples, hops, pears, red raspberries, spearmint oil, and sweet cherries, and ranks high in the production of apricots, asparagus, dry edible peas, grapes, lentils, peppermint oil, and potatoes.\",\n          \"The remainder of the state consists of deep temperate rainforests in the west, mountain ranges in the west, central, northeast, and far southeast, and a semi-arid basin region in the east, central, and south, given over to intensive agriculture.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"washington officially the state of washington is a state in the pacific northwest region of the western united states\",\n          \"washington is the nation s largest producer of apples hops pears red raspberries spearmint oil and sweet cherries and ranks high in the production of apricots asparagus dry edible peas grapes lentils peppermint oil and potatoes\",\n          \"the remainder of the state consists of deep temperate rainforests in the west mountain ranges in the west central northeast and far southeast and a semi arid basin region in the east central and south given over to intensive agriculture\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_words\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 5,\n        \"max\": 59,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          19,\n          43,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tfidf_scores\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMIsC62iqpa6"
      },
      "source": [
        "###Compute a Centroid Representation of the Article\n",
        "Next, we'll compute the centroid of the TF-IDF vectors for all of the sentences in the article. This centroid vector will be the average of all of the sentence-level TF-IDF vectors, and will hence represent the semantic content of the article as a whole. This step is necessary because we'll be using **Maximum Marginal Relevance (MMR)** to identify the most representative sentence from each passage of text, and MMR works by choosing the sentence from each passage that is most similar to the document overall, while minimizing redundancy among the set of chosen sentences.\n",
        "\n",
        "Run the code cell below to compute a centroid vector for all of the sentences in the article."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utRiXdUjChGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54080699-7cd7-471f-e970-d56329cc2d9b"
      },
      "source": [
        "#compute the centroid of the TF-IDF vectors for all of the sentences in the article\n",
        "centroid = np.reshape(np.mean(df.tfidf_scores, axis=0), (1, -1))\n",
        "\n",
        "#show the first few values in the centroid vector\n",
        "centroid[0, :10]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.01321761, 0.0196626 , 0.00609891, 0.00609891, 0.00749022,\n",
              "       0.01103094, 0.00776377, 0.01443063, 0.00792848, 0.01058928])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bNGa-2oLjMX"
      },
      "source": [
        "###Calculating Maximum Marginal Relevance (MMR)\n",
        "Next, let's implement a function that will identify the sentence with the Maximum Marginal Relevance (MMR) score in each paragraph. The MMR formula is used to assign each sentence in a paragraph a score based on:\n",
        "1. How similar the sentence is to the article as a whole (i.e., to the article's centroid); and\n",
        "2. How redundant the semantic content of each sentence is relative to the semantic content of any already-chosen summary sentences.\n",
        "\n",
        "The idea with MMR is thus to find a group of sentences that summarize the overall article without being excessively redundant, which seems to be a reasonable strategy.\n",
        "\n",
        "Run the code cell below to add the `get_extractive_summary()` function to your Python program. Note that this function has a `lambda_value` parameter that controls the level of relevance vs. redundancy among the sentences in the summary. Values of this parameter can range from 0.0 to 1.0. Smaller values of this parameter yield a summary whose sentences are more similar to the article as a whole, but which may also contain more redundant information. Larger values, by contrast, will yield a summary whose sentences will be less cohesive, but which will express a wider variety of content."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WntI1ifCg3k"
      },
      "source": [
        "#define a function that will generate an extractive summary of the article's text by identifying the best\n",
        "#representative, non-redundant sentence in each paragraph; i.e., the sentence with the Maximum Marginal Relevance (MMR).\n",
        "def get_extractive_summary(lambda_value):\n",
        "  #NOTE: the lambda_value parameter controls the level of relevance vs. redundancy among the sentences in the summary\n",
        "  summary_sentences = []\n",
        "  for paragraph_id in range(len(paragraphs)): #for each paragraph ID\n",
        "    #extract the TF-IDF scores for this paragraph's sentences from the dataframe\n",
        "    df_sentences = df[df.paragraph_id == paragraph_id]\n",
        "    #identify the sentence with the Maximum Marginal Relevance (MMR) for this paragraph\n",
        "    maximum_marginal_relevance = -np.inf #holds the MMR for the sentences in this paragraph, initialized to negative infinity\n",
        "    best_sentence = None #holds the sentence with the MMR\n",
        "    for sentence in df_sentences.itertuples(): #for each sentence in this paragraph\n",
        "      #calculate the cosine similarity between this sentence's TF-IDF scores and the article's centroid\n",
        "      similarity_to_article = cosine_similarity(np.reshape(sentence.tfidf_scores, (1, -1)), centroid)[0][0]\n",
        "      #calculate the maximum cosine similarity between this sentence and any already-chosen summary sentences\n",
        "      max_similarity_to_summary_sentence = -np.inf\n",
        "      for sentence_id, summary_sentence_tfidf_scores in summary_sentences:\n",
        "        similarity_to_summary_sentence = cosine_similarity(np.reshape(sentence.tfidf_scores, (1, -1)), np.reshape(summary_sentence_tfidf_scores, (1, -1)))[0][0]\n",
        "        if similarity_to_summary_sentence > max_similarity_to_summary_sentence:\n",
        "          max_similarity_to_summary_sentence = similarity_to_summary_sentence\n",
        "      #compute the marginal relevance for this sentence\n",
        "      marginal_relevance = ((1 - lambda_value) * similarity_to_article) - (lambda_value * max_similarity_to_summary_sentence)\n",
        "      if marginal_relevance > maximum_marginal_relevance:\n",
        "        maximum_marginal_relevance = marginal_relevance\n",
        "        best_sentence = (sentence.Index, sentence.tfidf_scores)\n",
        "    #add the sentence with the Maximum Marginal Relevance (MMR) for this paragraph to the collection of summary sentences\n",
        "    summary_sentences.append(best_sentence)\n",
        "\n",
        "  #construct and return the summary of the article\n",
        "  article_summary = ''\n",
        "  for sentence_id, _ in summary_sentences:\n",
        "    article_summary += df.iloc[sentence_id]['raw_text'] + ' '\n",
        "  return article_summary.strip()\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOkvUfElKbZ-"
      },
      "source": [
        "###Generate Extractive Text Summaries\n",
        "We're finally ready to generate extractive summaries of our article about the State of Washington. Yay!\n",
        "\n",
        "**TASK 04**:\n",
        ">Write a line of code in the cell below that will generate an extractive summary of the article about the State of Washington using a value for the `lambda_value` parameter of 0.2. This value will yield a summary that emphasizes similarity between each sentence and the article as a whole.\n",
        "\n",
        "**QUESTION 04**:\n",
        ">Which topics are mentioned in the extractive summary when the value of the lambda parameter is 0.2?\n",
        "* Agricultural products grown in Washington, such as apples, hops, and pears.\n",
        "* Mount Rainier.\n",
        "* Manufacturing industries in Washington, such as aircraft and shipbuilding.\n",
        "* Wine production in Washington.\n",
        "* Washington's high life expectancy and low unemployment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKJnDIRrCguO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f8f5a10-5ecd-4c86-e96c-0b3f4e0a80e9"
      },
      "source": [
        "#display a summary of the article using a value of 0.2 for the lambda parameter\n",
        "\n",
        "lambda_value = 0.2\n",
        "summary = get_extractive_summary(lambda_value)\n",
        "print(summary)\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Washington, officially the State of Washington, is a state in the Pacific Northwest region of the Western United States. Washington is the second most populous state on the West Coast and in the Western United States, after California. Washington is the nation's largest producer of apples, hops, pears, red raspberries, spearmint oil, and sweet cherries, and ranks high in the production of apricots, asparagus, dry edible peas, grapes, lentils, peppermint oil, and potatoes. Manufacturing industries in Washington include aircraft and missiles, shipbuilding, and other transportation equipment, food processing, metals and metal products, chemicals, and machinery. Washington is one of the wealthiest and most socially liberal states in the country.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqRG4YXPZjqa"
      },
      "source": [
        "**TASK 05**:\n",
        ">Write a line of code in the cell below that will generate an extractive summary of the article about the State of Washington using a value for the `lambda_value` parameter of 0.8. This value will yield a summary that emphasizes greater diversity among the topics that appear in the summary.\n",
        "\n",
        "**QUESTION 05**:\n",
        ">Which topics are mentioned in the extractive summary when the value of the lambda parameter is 0.8?\n",
        "* Agricultural products grown in Washington, such as apples, hops, and pears.\n",
        "* Mount Rainier.\n",
        "* Manufacturing industries in Washington, such as aircraft and shipbuilding.\n",
        "* Wine production in Washington.\n",
        "* Washington's high life expectancy and low unemployment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y73fiWfUKBTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4bca14f-0e24-4a5c-dd87-b902b0a09689"
      },
      "source": [
        "#display a summary of the article using a value of 0.8 for the labmda parameter\n",
        "\n",
        "lambda_value = 0.8\n",
        "summary1 = get_extractive_summary(lambda_value)\n",
        "print(summary1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Washington, officially the State of Washington, is a state in the Pacific Northwest region of the Western United States. Mount Rainier, an active stratovolcano, is the state's highest elevation, at almost 14,411 feet, and is the most topographically prominent mountain in the contiguous U.S. Washington ranks second only to California in wine production. Manufacturing industries in Washington include aircraft and missiles, shipbuilding, and other transportation equipment, food processing, metals and metal products, chemicals, and machinery. The state consistently ranks among the best for life expectancy and low unemployment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, extractive text summarization can automatically generate some very effective summaries!"
      ],
      "metadata": {
        "id": "6hjDlX7YHZJt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKGrWgvTVhSR"
      },
      "source": [
        "##Abstractive Text Summarization\n",
        "We'll next turn our attention to ***abstractive text summarization***, in which our goal is to generate new sentences that are semantically similar to the original text, but which did not appear in the original text. We'll be using n-gram language models and conditional probabilities for this purpose. If each word appears in the summary text with approximately the same probability as it appeared in the original text, then the generated summary text can be said to approximate the original text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXrSV-VBfbFa"
      },
      "source": [
        "### Load Data\n",
        "For this part of the lab assignment, we'll be using the complete text of the books *The Adventures of Sherlock Holmes* and *The Memoirs of Sherlock Holmes* as the basis for generating our abstractive summaries.\n",
        "\n",
        "After uploading the `Sherlock Holmes.txt` file, run the code cell below to make the text of these two Sherlock Holmes books available to your Python program. This code cell will also clean up the linefeed characters in the original text, and will use NLTK's sentence tokenizer to split the text into sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7PPnEdQC2hf"
      },
      "source": [
        "#load raw text from a file\n",
        "with open('Sherlock Holmes.txt', 'r') as f:\n",
        "  text = f.read()\n",
        "\n",
        "#replace linefeed characters\n",
        "text = text.replace('\\n\\n', ' ')\n",
        "text = text.replace('\\n', ' ')\n",
        "\n",
        "#split text into a list of sentences\n",
        "sentences = sent_tokenize(text)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOqw6u2fgouM"
      },
      "source": [
        "**TASK 06**:\n",
        ">Write a line of code in the cell below that will display the total number of sentences in the Sherlock Holmes books.\n",
        "\n",
        "**QUESTION 06**:\n",
        ">How many sentences are in the Sherlock Holmes books?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ogR7RMoDNW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a66162fa-0bd1-4691-a3d3-abc72fc446cd"
      },
      "source": [
        "#display the total number of sentences in the book\n",
        "\n",
        "total_sentences = len(sentences)  # Assuming sherlock_holmes_sentences contains all sentences\n",
        "print(\"Total number of sentences in the Sherlock Holmes books:\", total_sentences)\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of sentences in the Sherlock Holmes books: 9097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULAm7zEXmJIO"
      },
      "source": [
        "###Tokenize Sentences Into Lists\n",
        "Next, we'll tokenize each sentence into a list whose elements contain the words and symbols that together comprise the sentence. This is necessary because NLTK's `ngrams()` function (which we'll use to generate n-grams for our language models) requires input sentences to be in the form of tokenized lists. Note that tokens are different from words, since tokens can also be punctuation symbols.\n",
        "\n",
        "Run the code cell below to convert all of the sentences from the Sherlock Holmes books into lists by using NLTK's word tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWEs6MXvG5q4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94434607-ca19-41d3-9879-68ee89f0fe5f"
      },
      "source": [
        "#tokenize each sentence into a list of words and symbols\n",
        "sentences = [word_tokenize(sentence) for sentence in sentences]\n",
        "\n",
        "#show the tokens for the 100th sentence. Note that punctuation symbols\n",
        "#are also tokens!\n",
        "sentences[0]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'Adventures', 'of', 'Sherlock', 'Holmes', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tjL4qn2nQyg"
      },
      "source": [
        "**TASK 07**:\n",
        ">Write some code in the cell below that will compute and display the average number of tokens per sentence for the sentences in the Sherlock Holmes books.\n",
        "\n",
        "**QUESTION 07**:\n",
        ">What is the average number of tokens per sentence for the sentences in the Sherlock Holmes books? Record your answer using three decimals of precision (e.g., 21.934)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUaElZYHHPxC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc003d79-5564-45f1-b231-0f320570457f"
      },
      "source": [
        "# Calculate the total number of tokens\n",
        "total_tokens = sum(len(word_tokenize) for word_tokenize in sentences)\n",
        "\n",
        "# Calculate the total number of sentences\n",
        "total_sentences = len(sentences)\n",
        "\n",
        "# Compute the average number of tokens per sentence\n",
        "average_tokens_per_sentence = total_tokens / total_sentences\n",
        "\n",
        "# Display the average number of tokens per sentence\n",
        "print(\"Average number of tokens per sentence in the Sherlock Holmes books:\", round(average_tokens_per_sentence, 3))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average number of tokens per sentence in the Sherlock Holmes books: 26.263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mUDibjTplAw"
      },
      "source": [
        "###Convert Tokenized Sentences to N-Grams\n",
        "Next, let's write a function that will convert a tokenized sentence into a list of n-grams of size `n`. Remember, n-grams allow us to capture more context than individual words, since we can include concepts such as *bad traffic*, *soft kitty*, or *University of Washington*. By considering these short sequences of words, we will be able to calculate the probability of any word being the next word to appear in a sequence. For example, what word most likely comes next in this sequence?: *My favorite book ________*\n",
        "\n",
        "As you can see, your mind can make a reasonable guess about the next word in a sequence. In the above example, you probably chose the word **\"is\"** rather than some other word such as **\"tastes\"**. Why? Because your mind has calculated the conditional probability of the next word in the sequence based on your past experience with the English language. Put differently, you know that someone is much more likely to say \"My favorite book is...\" than \"My favorite book tastes...\", even though both options *could* occur.\n",
        "\n",
        "Run the code cell below to define a function that will convert a tokenized sentence into a list of n-grams of size `n`. Note that the function left-pads each sentence with an appropriate number of `<s>` start-of-sentence tags, depending on the value of `n`. This will allow us to figure out the probability of any word being the first word in a sentence. We also append an `</s>` end-of-sentence tag to the end of every sentence so that we will be able to identify n-grams that appear at the end of sentences. Note also that the n-grams are stored as tuples with the format: `((n - 1 previous words), next word in sequence)`. This format will be very useful when we begin calculating the probabailities of different words appearing next in a sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn2ernJNJLQq"
      },
      "source": [
        "#define a function that will convert a tokenized sentence into a list of n-grams of size n.\n",
        "def get_ngrams(sentence, n):\n",
        "  #left-pad the sentence with an appropriate number of start-of-sentence tags. This is necessary\n",
        "  #to allow the conditional probability of the first word in each sentence to be computed.\n",
        "  sentence = (n - 1) * ['<s>'] + sentence\n",
        "  #right-pad the sentence with an end-of-sentence tag. This is necessary to allow the conditional\n",
        "  #probability of ending the sentence to be computed.\n",
        "  sentence.append('</s>')\n",
        "  #generate a list of n-grams for the sentence\n",
        "  n_grams = list(ngrams(sentence, n))\n",
        "  #convert n-grams into tuples with the format: ((n - 1 previous words), next word in sequence)\n",
        "  n_grams = [((n_gram[:-1]), n_gram[-1]) for n_gram in n_grams]\n",
        "  return n_grams"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M90nADO8t3aR"
      },
      "source": [
        "**TASK 08**:\n",
        ">Write a line of code in the cell below that will display all of the 3-grams (i.e., `n = 3`) for the sentence at index location 999 within the `sentences` collection.\n",
        "\n",
        "**QUESTION 08**:\n",
        ">What is the first 3-gram for the sentence that appears at index location 999 in the `sentences` collection?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf675D-4LZXL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a31b377d-d980-47b9-df2d-d88c79a639d5"
      },
      "source": [
        "#display all of the 3-grams for the sentence that appears at index location 999 in the 'sentences' list\n",
        "# Assuming you have already defined the sentences collection and imported the necessary libraries\n",
        "n = 3  # Define the value of n for 3-grams\n",
        "sentence = sentences[999]  # Get the sentence at index location 999\n",
        "three_grams_sentence_999 = get_ngrams(sentence, n)  # Get the 3-grams for the sentence\n",
        "print(\"3-grams for the sentence at index 999:\", three_grams_sentence_999)\n",
        "\n",
        "\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3-grams for the sentence at index 999: [(('<s>', '<s>'), 'You'), (('<s>', 'You'), 'have'), (('You', 'have'), 'really'), (('have', 'really'), 'done'), (('really', 'done'), 'very'), (('done', 'very'), 'well'), (('very', 'well'), 'indeed'), (('well', 'indeed'), '.'), (('indeed', '.'), '</s>')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aVJeYscwFda"
      },
      "source": [
        "###Define Punctuation Symbols\n",
        "Next, we'll define what constitutes a punctuation symbol within our text. Since we're not cleaning this text in the same way that we did when working with feature vectors, all of the punctuation symbols remain in the text. For the most part, we can use Python's standard set of punctuation symbols, but we'll need to add a few more to accommodate directional closing double-quotes and single-quotes.\n",
        "\n",
        "Run the code cell below to define the punctuation symbols."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8hT-MV1CMQU"
      },
      "source": [
        "#define punctuation symbols\n",
        "punctuation = string.punctuation + '”’'"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1pLqac0xF9P"
      },
      "source": [
        "###Define a Language Model Class\n",
        "We've now reached a point where we can define a class that will allow us to construct and work with language models based on n-grams. Each language model is constructed based on a set of input sentences and word\n",
        "sequences (n-grams) of length `n`. The language model consists of a collection of word sequences of length\n",
        "(n - 1) and the set of possible words that might immediately follow each word sequence. Each candidate word that might follow a particular sequence of words has a specific probability of being the next word in the sequence.\n",
        "\n",
        "Run the code cell below to add the `Language_Model()` class to your Python project.\n",
        "\n",
        "***Study the code and the comments in this class very carefully so that you will understand how the language model is built and how the conditional probabilities are calculated!***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjF1u5s9VOYR"
      },
      "source": [
        "#Define a language model class. A language model is constructed based on a set of input sentences and word\n",
        "#sequences (n-grams) of length n. The language model consists of a collection of word sequences of length\n",
        "#(n - 1) and the set of possible words that might follow each word sequence. Each candidate word that might\n",
        "#follow a particular sequence of words has a specific probability of being the next word in the sequence.\n",
        "class Language_Model():\n",
        "  #define the class's initialization function\n",
        "  def __init__(self, n, sentences): #n = the size of n-grams to use; sentences = the tokenized sentences from which to construct the language model.\n",
        "    self.end_of_sentence_tag = '</s>' #the tag that marks the end of a sentence\n",
        "    self.n = n #the number of words that constitute an n-gram\n",
        "    self.n_gram_count = {} #a dictionary that holds the number of times each n-gram has been observed in the text. Keys = n-grams, values = n-gram counts\n",
        "    self.sentences = sentences #the sentences from which to construct the language model\n",
        "    self.start_of_sentence_sequence = tuple(['<s>' for _ in range(n - 1)]) #a tuple containing the appropriate number of successive start-of-sentence tags (based on n) to indicate the beginning of a new sentence\n",
        "    self.word_sequences = {} #a dictionary containing sequences of words (keys) and a list of candidate words that may follow each sequence (values)\n",
        "\n",
        "    #build the language model\n",
        "    for sentence in sentences: #for each sentence\n",
        "      #get the n-grams for this sentence\n",
        "      n_grams = get_ngrams(sentence, n)\n",
        "      #for each n-gram in this sentence\n",
        "      for n_gram in n_grams:\n",
        "        #if this n-gram has been seen previously (if the n-gram exists as a key in the dictionary)\n",
        "        if n_gram in self.n_gram_count:\n",
        "          self.n_gram_count[n_gram] += 1 #increment the number of times this n-gram has been observed\n",
        "        else: #if this is the first time this n-gram has been seen\n",
        "          self.n_gram_count[n_gram] = 1 #add this n-gram to the dictionary and set its number of observations to 1\n",
        "        #extract the sequence of previous words and the next word from this n-gram\n",
        "        word_sequence, next_word = n_gram\n",
        "        #if this sequence of words has already been observed\n",
        "        if word_sequence in self.word_sequences:\n",
        "          self.word_sequences[word_sequence].append(next_word) #add the next word to this sequence's list of next words\n",
        "        else: #if this sequence of words has not yet been observed\n",
        "          self.word_sequences[word_sequence] = [next_word] #add this word sequence to the dictionary and initialize its list of next words\n",
        "\n",
        "    #calculate conditional probabilities for all of the words that might follow each sequence of words\n",
        "    for word_sequence in self.word_sequences:\n",
        "      #get the raw word frequencies for each word that might follow this word sequence\n",
        "      freq_dist = FreqDist(self.word_sequences[word_sequence])\n",
        "      #compute the conditional probabilities for each word and store them in a list that is sorted\n",
        "      #from the most probable word to the least probable word\n",
        "      word_probabilities = [(word, freq_dist.freq(word)) for word, frequency in freq_dist.most_common()]\n",
        "      #replace the previous list of words that might follow this word sequence with the list of words and probabilities\n",
        "      self.word_sequences[word_sequence] = word_probabilities\n",
        "\n",
        "  #define a function that will return the next word (or symbol) in a sequence. The likelihood of any of the\n",
        "  #possible words being returned depends on its conditional probability, given the word sequence.\n",
        "  def get_next_word(self, word_sequence):\n",
        "    #get a random number between 0 and 1 to serve as the probability threshold\n",
        "    random_probability_threshold = np.random.random()\n",
        "    #define a variable to hold the cumulative probability\n",
        "    cumulative_probability = 0.0\n",
        "    #define a variable to hold the next word in the sequence\n",
        "    next_word = None\n",
        "    #determine which word should appear next in the sequence based on the words' conditional probabilities,\n",
        "    #for each possible next word\n",
        "    for word, word_probability in self.word_sequences[word_sequence]:\n",
        "      #add this word's probability of being next in the sequence to the cunulative probability\n",
        "      cumulative_probability += word_probability\n",
        "      #if the cumulative probability exceeds the randomly chosen probability threshold\n",
        "      if cumulative_probability >= random_probability_threshold:\n",
        "        #assign the current word to be the next word in the sequence, and exit the loop immediately\n",
        "        next_word = word\n",
        "        break\n",
        "    return next_word\n",
        "\n",
        "  #define a function that will generate a sentence based on the language model\n",
        "  def generate_sentence(self):\n",
        "    #define a variable to hold the words (and symbols) that comprise the sentence\n",
        "    sentence = ''\n",
        "    #initialize the word sequence to the start-of-sentence sequence\n",
        "    word_sequence = self.start_of_sentence_sequence\n",
        "    #get the first word in the sentence\n",
        "    word = self.get_next_word(word_sequence)\n",
        "    #while the end of the sentence has not yet been reached\n",
        "    while word != self.end_of_sentence_tag:\n",
        "      #add this word (or symbol) to the sentence\n",
        "      sentence += ' ' + word\n",
        "      #construct the next word sequence\n",
        "      word_sequence = word_sequence[1:] + (word,)\n",
        "      #get the next word (or symbol) in the sentence\n",
        "      word = self.get_next_word(word_sequence)\n",
        "    #cleanup punctuation and spacing\n",
        "    for symbol in punctuation:\n",
        "      sentence = sentence.replace(' ' + symbol, symbol)\n",
        "    for symbol in '“‘':\n",
        "      sentence = sentence.replace(symbol + ' ', symbol)\n",
        "    sentence = sentence.replace('n’ t', 'n’t')\n",
        "    sentence = sentence.replace('’ s ', '’s ')\n",
        "    sentence = sentence.replace('’ m ', '’m ')\n",
        "    return sentence.strip()\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo2sW1bpzm-c"
      },
      "source": [
        "###Generate Language Models\n",
        "We now have everything that we need to generate language models based on n-grams. Yay!\n",
        "\n",
        "Run the code cell below to generate a language model for our collection of sentences using 3-grams (i.e., `n = 3`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOMgG6mweDmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe7e72a3-9b46-49d0-fd17-eaef53c17265"
      },
      "source": [
        "#generate a language model using 3-grams\n",
        "n3_model = Language_Model(3, sentences)\n",
        "\n",
        "#show all of the tokens that might follow the phrase 'Sherlock Holmes', and their\n",
        "#probabilities of occurance\n",
        "n3_model.word_sequences[('Sherlock', 'Holmes')]"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',', 0.1897810218978102),\n",
              " ('.', 0.15328467153284672),\n",
              " ('was', 0.10218978102189781),\n",
              " ('had', 0.058394160583941604),\n",
              " ('’', 0.051094890510948905),\n",
              " ('sat', 0.051094890510948905),\n",
              " ('and', 0.029197080291970802),\n",
              " ('as', 0.021897810218978103),\n",
              " ('laughed', 0.021897810218978103),\n",
              " ('stopped', 0.014598540145985401),\n",
              " ('returned', 0.014598540145985401),\n",
              " ('took', 0.014598540145985401),\n",
              " ('sprang', 0.014598540145985401),\n",
              " ('pulled', 0.014598540145985401),\n",
              " ('she', 0.0072992700729927005),\n",
              " ('by', 0.0072992700729927005),\n",
              " ('staggered', 0.0072992700729927005),\n",
              " ('were', 0.0072992700729927005),\n",
              " ('welcomed', 0.0072992700729927005),\n",
              " ('impatient', 0.0072992700729927005),\n",
              " ('clapped', 0.0072992700729927005),\n",
              " ('alone', 0.0072992700729927005),\n",
              " ('!', 0.0072992700729927005),\n",
              " ('cases', 0.0072992700729927005),\n",
              " ('closed', 0.0072992700729927005),\n",
              " ('seemed', 0.0072992700729927005),\n",
              " ('upon', 0.0072992700729927005),\n",
              " ('glanced', 0.0072992700729927005),\n",
              " ('looked', 0.0072992700729927005),\n",
              " ('hailed', 0.0072992700729927005),\n",
              " ('standing', 0.0072992700729927005),\n",
              " ('ran', 0.0072992700729927005),\n",
              " ('leaned', 0.0072992700729927005),\n",
              " ('left', 0.0072992700729927005),\n",
              " ('stepped', 0.0072992700729927005),\n",
              " ('pushed', 0.0072992700729927005),\n",
              " ('rather', 0.0072992700729927005),\n",
              " ('replaced', 0.0072992700729927005),\n",
              " ('rubbed', 0.0072992700729927005),\n",
              " ('cocked', 0.0072992700729927005),\n",
              " ('picked', 0.0072992700729927005),\n",
              " ('recovered', 0.0072992700729927005),\n",
              " ('placed', 0.0072992700729927005),\n",
              " ('who', 0.0072992700729927005),\n",
              " ('I', 0.0072992700729927005),\n",
              " ('shook', 0.0072992700729927005),\n",
              " ('?', 0.0072992700729927005),\n",
              " ('swallowed', 0.0072992700729927005)]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFUGwJQ00XSE"
      },
      "source": [
        "**TASK 09**:\n",
        ">Write a line of code in the cell below that will display the 10 words that are most likely to appear as the first word in a sentence in the Sherlock Holmes books. ***Tip***: You will need to get the values out of the `n3_model` language model's `word_sequences[]` collection for the language model's `start_of_sentence_sequence` property.\n",
        "\n",
        "**QUESTION 09**:\n",
        ">Which <u>word</u> (as opposed to a punctuation symbol) is most likely to appear as the first word in a sentence in the Sherlock Holmes books?\n",
        "* It\n",
        "* The\n",
        "* I\n",
        "* You"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd07xm_3e-NW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a063819f-4eb7-4a8a-9958-31b844d2d325"
      },
      "source": [
        "#display the words that are most likely to appear as the first word in a sentence\n",
        "\n",
        "# Generate a language model using 3-grams\n",
        "n3_model = Language_Model(3, sentences)\n",
        "\n",
        "# Get the probabilities of occurrence for the next word after the start-of-sentence sequence\n",
        "probabilities = n3_model.word_sequences[n3_model.start_of_sentence_sequence]\n",
        "\n",
        "# Extract the 10 most likely words and their probabilities\n",
        "top_10_words = sorted(probabilities, key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "# Display the top 10 words\n",
        "print(\"Top 10 words most likely to appear as the first word in a sentence:\")\n",
        "for word, probability in top_10_words:\n",
        "    print(f\"{word}: {probability}\")\n",
        "\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 words most likely to appear as the first word in a sentence:\n",
            "“: 0.22413982631636803\n",
            "I: 0.10882708585247884\n",
            "It: 0.05518302737166099\n",
            "The: 0.0517753105419369\n",
            "He: 0.0434209079916456\n",
            "You: 0.026052544794987358\n",
            "But: 0.025283060349565793\n",
            "There: 0.02286468066395515\n",
            "‘: 0.017588215895350114\n",
            "We: 0.016928657799274487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcggTZH93a83"
      },
      "source": [
        "###Generate Abstractive Sentences Using the Language Model\n",
        "Now it's time to use our language model to generate some new sentences that don't appear in the original text. Nevertheless, our new sentences should seem  similar to the kinds of sentences that we would expect to appear in a Sherlock Holmes book, given that the model was trained using Sherlock Holmes books.\n",
        "\n",
        "Run the code cell below to generate five new sentences using our `n = 3` language model. Since the value of `n` is relatively small in this particular language model, we should not expect the sentences to make perfect sense."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_EbXMbSUPff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d4e57de-21e4-412e-8a55-7a5cebaca6de"
      },
      "source": [
        "#set the seed for the random number generator (to ensure consistent results)\n",
        "np.random.seed(123)\n",
        "\n",
        "#generate five sentences for the n=3 language model\n",
        "for i in range(5):\n",
        "  sentence = n3_model.generate_sentence()\n",
        "  print(sentence, '\\n')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This he unpacked with the smooth white country road at three in the house. \n",
            "\n",
            "“I shall go mad if it was also an ex-Australian. \n",
            "\n",
            "She was flattered by the evening before I can write with all the morning. \n",
            "\n",
            "I can come up, and are too recent in the windows were broken and blocked with wooden boards, while to me, then? \n",
            "\n",
            "She listened for an instant, and an engagement, for he became engaged to her husband’s injunctions to the definite conception of an old woman ran out in the most pleasant fashion until his eyes, and the pencil which Holmes, for I lay tossing half the doctors in’ 83 that I am saved!” ejaculated Phelps. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFUACWcG5SW_"
      },
      "source": [
        "One of the interesting things about language models based on n-grams is that as the value of `n` increases, the newly generated sentences seem more and more natural. The problem, however, is that as the value of `n` increases, so too does the probability of exactly reproducing one of the actual sentences from the original text. For this reason, it is generally recommended to use values of `n` of between 3 and 5.\n",
        "\n",
        "**TASK 10**:\n",
        ">Write some code in the cell below that will train a language model for `n = 5`, and then generate five new sentences using your `n = 5` language model. ***NOTE***: Do <u>not</u> change the random seed value that appears in the cell. If you do, you will be unable to answer Question 10.\n",
        "\n",
        "**QUESTION 10**:\n",
        ">What is the fifth sentence generated by the `n = 5` model?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVFdqNGPUQlK"
      },
      "source": [
        "#generate a language model using 5-grams\n",
        "n4_model = Language_Model(5, sentences)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEolxrEwVdc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbf75d47-d9a6-4c82-c380-144c44b4c01d"
      },
      "source": [
        "#set the seed for the random number generator (to ensure consistent results)\n",
        "np.random.seed(123)\n",
        "\n",
        "#generate five sentences for the n=5 model\n",
        "\n",
        "for i in range(5):\n",
        "  sentence = n4_model.generate_sentence()\n",
        "  print(sentence, '\\n')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This he unpacked with the help of a policeman and of a medical man, he returned. \n",
            "\n",
            "But here an unexpected and singular difficulty presented itself. \n",
            "\n",
            "“The string is exceedingly interesting,” he remarked. \n",
            "\n",
            "I’m not rich, but still I had such faith in Holmes’ judgment that I felt that there must be some radical mistake in my calculations. \n",
            "\n",
            "My wife was on a visit to Birmingham. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnalYBNMb3Jz"
      },
      "source": [
        "As you can see, the sentences generated by the `n = 5` model seem much more natural and understandable than the sentences generated by the `n = 3` model. Nevertheless, it is important to remember that these sentences are being generated statistically -- our Python program does not actually ***understand*** the meaning of the sentences that it is writing!\n",
        "\n",
        "Before taking your lab quiz, I'd suggest selecting *Runtime >> Restart and run all* from the menu, and then waiting for the entire notebook to run from start to finish. This will ensure that any issues relating to random number generation are eliminated.\n",
        "\n",
        "##End of Lab Assignment 05!"
      ]
    }
  ]
}